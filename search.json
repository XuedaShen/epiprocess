[{"path":"https://cmu-delphi.github.io/epiprocess/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 epiprocess authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/advanced.html","id":"recycling-outputs","dir":"Articles","previous_headings":"","what":"Recycling outputs","title":"Advanced sliding with nonstandard outputs","text":"computation returns single atomic value, epi_slide() internally try recycle output size stable (sense described ). can use advantage, example, order compute trailing average marginally geo values, demonstrate simple synthetic example. slide computation returns atomic vector (rather single value) epi_slide() checks whether return length ensures size stability, , uses fill new column. example, next computation gives result last one. However, output atomic vector (rather single value) size stable, epi_slide() throws error. example, trying return 2 things 3 states.","code":"library(epiprocess) library(dplyr)  df <- tibble(   geo_value = rep(c(\"ca\", \"fl\", \"pa\"), each = 3),   time_value = rep(seq(as.Date(\"2020-06-01\"), as.Date(\"2020-06-03\"),                        by = \"day\"), length.out = length(geo_value)),   x = 1:length(geo_value) + 0.01 * rnorm(length(geo_value)), ) %>%   as_epi_df()  # 2-day trailing average, per geo value df %>%    group_by(geo_value) %>%   epi_slide(x_2dav = mean(x), n = 2) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 4 ## # Groups:   geo_value [3] ##   geo_value time_value     x x_2dav ## * <chr>     <date>     <dbl>  <dbl> ## 1 ca        2020-06-01  1.01   1.01 ## 2 ca        2020-06-02  2.01   1.51 ## 3 ca        2020-06-03  3.01   2.51 ## 4 fl        2020-06-01  4.01   4.01 ## 5 fl        2020-06-02  5.00   4.50 ## 6 fl        2020-06-03  6.00   5.50 ## 7 pa        2020-06-01  6.98   6.98 ## 8 pa        2020-06-02  8.03   7.50 ## 9 pa        2020-06-03  8.99   8.51 # 2-day trailing average, marginally  df %>%    epi_slide(x_2dav = mean(x), n = 2) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 4 ##   geo_value time_value     x x_2dav ## * <chr>     <date>     <dbl>  <dbl> ## 1 ca        2020-06-01  1.01   4.00 ## 2 fl        2020-06-01  4.01   4.00 ## 3 pa        2020-06-01  6.98   4.00 ## 4 ca        2020-06-02  2.01   4.50 ## 5 fl        2020-06-02  5.00   4.50 ## 6 pa        2020-06-02  8.03   4.50 ## 7 ca        2020-06-03  3.01   5.51 ## 8 fl        2020-06-03  6.00   5.51 ## 9 pa        2020-06-03  8.99   5.51 df %>%    epi_slide(y_2dav = rep(mean(x), 3), n = 2) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 4 ##   geo_value time_value     x y_2dav ## * <chr>     <date>     <dbl>  <dbl> ## 1 ca        2020-06-01  1.01   4.00 ## 2 fl        2020-06-01  4.01   4.00 ## 3 pa        2020-06-01  6.98   4.00 ## 4 ca        2020-06-02  2.01   4.50 ## 5 fl        2020-06-02  5.00   4.50 ## 6 pa        2020-06-02  8.03   4.50 ## 7 ca        2020-06-03  3.01   5.51 ## 8 fl        2020-06-03  6.00   5.51 ## 9 pa        2020-06-03  8.99   5.51 df %>%    epi_slide(x_2dav = rep(mean(x), 2), n = 2) ## Error in `Abort()`: ## ! If the slide computations return atomic vectors, then they must each ## have a single element, or else one element per appearance of the reference ## time value in the local window."},{"path":"https://cmu-delphi.github.io/epiprocess/articles/advanced.html","id":"multi-column-outputs","dir":"Articles","previous_headings":"","what":"Multi-column outputs","title":"Advanced sliding with nonstandard outputs","text":"Now move outputs data frames single row multiple columns. Working type output structure fact already demonstrated slide vignette. set as_list_col = TRUE call epi_slide(), resulting epi_df object returned epi_slide() list column containing slide values. use as_list_col = FALSE (default epi_slide()), function unnests (sense tidyr::unnest()) list column , resulting epi_df multiple new columns containing slide values. default name unnested columns prefixing name assigned list column () onto column names output data frame slide computation (x_2dav x_2dma) separated \"_\". can use names_sep = NULL (gets passed tidyr::unnest()) drop prefix associated list column name, naming unnested columns. Furthermore, epi_slide() recycle single row data frame needed order make result size stable, just like case atomic values.","code":"df2 <- df %>%    group_by(geo_value) %>%   epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),             n = 2, as_list_col = TRUE)  class(df2$a) ## [1] \"list\" length(df2$a) ## [1] 9 df2$a[[2]] ##     x_2dav    x_2dma ## 1 1.508465 0.7455431 df %>%    group_by(geo_value) %>%   epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),             n = 2, as_list_col = FALSE) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 5 ## # Groups:   geo_value [3] ##   geo_value time_value     x a_x_2dav a_x_2dma ## * <chr>     <date>     <dbl>    <dbl>    <dbl> ## 1 ca        2020-06-01  1.01     1.01    0     ## 2 ca        2020-06-02  2.01     1.51    0.746 ## 3 ca        2020-06-03  3.01     2.51    0.744 ## 4 fl        2020-06-01  4.01     4.01    0     ## 5 fl        2020-06-02  5.00     4.50    0.736 ## 6 fl        2020-06-03  6.00     5.50    0.741 ## 7 pa        2020-06-01  6.98     6.98    0     ## 8 pa        2020-06-02  8.03     7.50    0.778 ## 9 pa        2020-06-03  8.99     8.51    0.712 df %>%    group_by(geo_value) %>%   epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),             n = 2, as_list_col = FALSE, names_sep = NULL) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 5 ## # Groups:   geo_value [3] ##   geo_value time_value     x x_2dav x_2dma ## * <chr>     <date>     <dbl>  <dbl>  <dbl> ## 1 ca        2020-06-01  1.01   1.01  0     ## 2 ca        2020-06-02  2.01   1.51  0.746 ## 3 ca        2020-06-03  3.01   2.51  0.744 ## 4 fl        2020-06-01  4.01   4.01  0     ## 5 fl        2020-06-02  5.00   4.50  0.736 ## 6 fl        2020-06-03  6.00   5.50  0.741 ## 7 pa        2020-06-01  6.98   6.98  0     ## 8 pa        2020-06-02  8.03   7.50  0.778 ## 9 pa        2020-06-03  8.99   8.51  0.712 df %>%    epi_slide(a = data.frame(x_2dav = mean(x), x_2dma = mad(x)),             n = 2, as_list_col = FALSE, names_sep = NULL) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 5 ##   geo_value time_value     x x_2dav x_2dma ## * <chr>     <date>     <dbl>  <dbl>  <dbl> ## 1 ca        2020-06-01  1.01   4.00   4.41 ## 2 fl        2020-06-01  4.01   4.00   4.41 ## 3 pa        2020-06-01  6.98   4.00   4.41 ## 4 ca        2020-06-02  2.01   4.50   3.68 ## 5 fl        2020-06-02  5.00   4.50   3.68 ## 6 pa        2020-06-02  8.03   4.50   3.68 ## 7 ca        2020-06-03  3.01   5.51   3.72 ## 8 fl        2020-06-03  6.00   5.51   3.72 ## 9 pa        2020-06-03  8.99   5.51   3.72"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/advanced.html","id":"multi-row-outputs","dir":"Articles","previous_headings":"","what":"Multi-row outputs","title":"Advanced sliding with nonstandard outputs","text":"slide computation outputs data frame one row, behavior analogous slide computation outputs atomic vector. Meaning, epi_slide() check result size stable, , fill new column(s) resulting epi_df object appropriately. can convenient modeling following sense: can, example, fit sliding forecasting model pooling data different locations, return separate forecasts common model location. use synthetic example demonstrate idea abstractly simply.","code":"df$y <- 2 * df$x + 0.05 * rnorm(length(df$x))  df %>%   epi_slide(function(d, ...) {     obj <- lm(y ~ x, data = d)     return(       as.data.frame(         predict(obj, newdata = d %>%                    group_by(geo_value) %>%                   filter(time_value == max(time_value)),                  interval = \"prediction\", level = 0.9)       ))   }, n = 2, new_col_name = \"fc\", names_sep = NULL) ## An `epi_df` object, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 21:19:34 ##  ## # A tibble: 9 × 7 ##   geo_value time_value     x     y   fit   lwr   upr ## * <chr>     <date>     <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 ca        2020-06-01  1.01  1.94  1.93  1.66  2.20 ## 2 fl        2020-06-01  4.01  7.97  8.00  7.77  8.23 ## 3 pa        2020-06-01  6.98 14.0  14.0  13.7  14.3  ## 4 ca        2020-06-02  2.01  3.98  3.97  3.88  4.06 ## 5 fl        2020-06-02  5.00  9.98  9.99  9.90 10.1  ## 6 pa        2020-06-02  8.03 16.0  16.1  16.0  16.2  ## 7 ca        2020-06-03  3.01  6.03  6.02  5.96  6.08 ## 8 fl        2020-06-03  6.00 12.0  12.0  11.9  12.0  ## 9 pa        2020-06-03  8.99 17.9  18.0  17.9  18.0"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/advanced.html","id":"version-aware-forecasting-revisited","dir":"Articles","previous_headings":"","what":"Version-aware forecasting, revisited","title":"Advanced sliding with nonstandard outputs","text":"Finally, revisit COVID-19 forecasting example archive vignette order demonstrate last point realistic setting. First, fetch versioned data build archive. Next, extend ARX function handle multiple geo values, since present case, grouping geo value slide computation run multiple geo values . Note , epix_slide() returns grouping variables, time_value, slide computations eventual returned tibble, need include geo_value column output data frame ARX computation. now make forecasts archive compare forecasts latest data.  can see forecasts, come training ARX model jointly CA FL, exhibit generally less variability wider prediction bands compared ones archive vignette, come training separate ARX model state. archive vignette, can see difference version-aware (right column) -unaware (left column) forecasting, well.","code":"library(delphi.epidata) library(data.table) library(ggplot2) theme_set(theme_bw())  y1 <- covidcast(   data_source = \"doctor-visits\",   signals = \"smoothed_adj_cli\",   time_type = \"day\",   geo_type = \"state\",   time_value = epirange(20200601, 20211201),   geo_values = \"ca,fl\",   issues = epirange(20200601, 20211201) ) %>% fetch_tbl()  y2 <- covidcast(   data_source = \"jhu-csse\",   signal = \"confirmed_7dav_incidence_prop\",   time_type = \"day\",   geo_type = \"state\",   time_value = epirange(20200601, 20211201),   geo_values = \"ca,fl\",   issues = epirange(20200601, 20211201) ) %>% fetch_tbl()  x <- y1 %>%   select(geo_value, time_value,     version = issue,     percent_cli = value   ) %>%   as_epi_archive()  epix_merge(x, y2 %>%   select(geo_value, time_value,     version = issue,     case_rate_7d_av = value   ) %>%   as_epi_archive(), all = TRUE ) library(tidyr) library(purrr) ##  ## Attaching package: 'purrr' ## The following object is masked from 'package:data.table': ##  ##     transpose prob_arx_args <- function(lags = c(0, 7, 14),                            ahead = 7,                            min_train_window = 20,                           lower_level = 0.05,                            upper_level = 0.95,                            symmetrize = TRUE,                            intercept = FALSE,                           nonneg = TRUE) {   return(list(lags = lags,                ahead = ahead,                min_train_window = min_train_window,               lower_level = lower_level,               upper_level = upper_level,               symmetrize = symmetrize,                intercept = intercept,               nonneg = nonneg)) }  prob_arx <- function(x, y, geo_value, time_value, args = prob_arx_args()) {     # Return NA if insufficient training data   if (length(y) < args$min_train_window + max(args$lags) + args$ahead) {     return(data.frame(geo_value = unique(geo_value), # Return geo value!                       point = NA, lower = NA, upper = NA))   }      # Set up x, y, lags list   if (!missing(x)) x <- data.frame(x, y)   else x <- data.frame(y)   if (!is.list(args$lags)) args$lags <- list(args$lags)   args$lags = rep(args$lags, length.out = ncol(x))      # Build features and response for the AR model, and then fit it   dat <-     tibble(i = 1:ncol(x), lag = args$lags) %>%     unnest(lag) %>%     mutate(name = paste0(\"x\", 1:nrow(.))) %>%     # One list element for each lagged feature     pmap(function(i, lag, name) {       tibble(geo_value = geo_value,              time_value = time_value + lag, # Shift back               !!name := x[,i])     }) %>%      # One list element for the response vector     c(list(       tibble(geo_value = geo_value,              time_value = time_value - args$ahead, # Shift forward               y = y))) %>%     # Combine them together into one data frame     reduce(full_join, by = c(\"geo_value\", \"time_value\")) %>%     arrange(time_value)   if (args$intercept) dat$x0 = rep(1, nrow(dat))   obj <- lm(y ~ . + 0, data = select(dat, -geo_value, -time_value))      # Use LOCF to fill NAs in the latest feature values (do this by geo value)   setDT(dat) # Convert to a data.table object by reference   cols <- setdiff(names(dat), c(\"geo_value\", \"time_value\"))   dat[, (cols) := nafill(.SD, type = \"locf\"), .SDcols = cols, by = \"geo_value\"]      # Make predictions   test_time_value = max(time_value)   point <- predict(obj, newdata = dat %>%                       dplyr::group_by(geo_value) %>%                      dplyr::filter(time_value == test_time_value))      # Compute bands   r <- residuals(obj)   s <- ifelse(args$symmetrize, -1, NA) # Should the residuals be symmetrized?   q <- quantile(c(r, s * r), probs = c(args$lower, args$upper), na.rm = TRUE)   lower <- point + q[1]   upper <- point + q[2]      # Clip at zero if we need to, then return   if (args$nonneg) {      point = pmax(point, 0)      lower = pmax(lower, 0)      upper = pmax(upper, 0)    }   return(data.frame(geo_value = unique(geo_value), # Return geo value!                     point = point, lower = lower, upper = upper)) } # Latest snapshot of data, and forecast dates x_latest <- epix_as_of(x, max_version = max(x$DT$version)) fc_time_values <- seq(as.Date(\"2020-08-01\"),                        as.Date(\"2021-12-01\"),                        by = \"1 month\")  # Simple function to produce forecasts k weeks ahead k_week_ahead <- function(x, ahead = 7, as_of = TRUE) {   if (as_of) {     x %>%       epix_slide(fc = prob_arx(percent_cli, case_rate_7d_av, geo_value, time_value,                                 args = prob_arx_args(ahead = ahead)),                   n = 120, ref_time_values = fc_time_values) %>%       mutate(target_date = time_value + ahead, as_of = TRUE,               geo_value = fc_geo_value)   }   else {     x_latest %>%        epi_slide(fc = prob_arx(percent_cli, case_rate_7d_av, geo_value, time_value,                                args = prob_arx_args(ahead = ahead)),                  n = 120, ref_time_values = fc_time_values) %>%       mutate(target_date = time_value + ahead, as_of = FALSE)    } }  # Generate the forecasts, and bind them together fc <- bind_rows(k_week_ahead(x, ahead = 7, as_of = TRUE),                 k_week_ahead(x, ahead = 14, as_of = TRUE),                 k_week_ahead(x, ahead = 21, as_of = TRUE),                 k_week_ahead(x, ahead = 28, as_of = TRUE),                 k_week_ahead(x, ahead = 7, as_of = FALSE),                 k_week_ahead(x, ahead = 14, as_of = FALSE),                 k_week_ahead(x, ahead = 21, as_of = FALSE),                 k_week_ahead(x, ahead = 28, as_of = FALSE))  # Plot them, on top of latest COVID-19 case rates  ggplot(fc, aes(x = target_date, group = time_value, fill = as_of)) +   geom_ribbon(aes(ymin = fc_lower, ymax = fc_upper), alpha = 0.4) +   geom_line(data = x_latest, aes(x = time_value, y = case_rate_7d_av),                 inherit.aes = FALSE, color = \"gray50\") +   geom_line(aes(y = fc_point)) + geom_point(aes(y = fc_point), size = 0.5) +    geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +   facet_grid(vars(geo_value), vars(as_of), scales = \"free\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +    theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/advanced.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Advanced sliding with nonstandard outputs","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidatab Doctor’s Visit API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/aggregation.html","id":"converting-to-tsibble-format","dir":"Articles","previous_headings":"","what":"Converting to tsibble format","title":"Aggregate signals over space and time","text":"manipulating wrangling time series data, tsibble already provides whole bunch useful tools. tsibble object (formerly, class tbl_ts) basically tibble (data frame) two specially-marked columns: index column representing time variable (defining order past present), key column identifying unique observational unit time point. fact, key can made number columns, just single one. epi_df object, index variable time_value, key variable typically geo_value (though need always case: example, age group variable another column, serve second key variable). epiprocess package thus provides implementation as_tsibble() epi_df objects, sets variables according defaults. can also set key variable(s) directly call as_tsibble(). Similar SQL keys, key uniquely identify time point (, key index together uniquely identify row), as_tsibble() throws error: can see, duplicate county names Massachusetts Vermont, caused error. Keying county name state name, however, work:","code":"library(tsibble)  xt <- as_tsibble(x) head(xt) ## # A tsibble: 6 x 5 [1D] ## # Key:       geo_value [1] ##   geo_value time_value cases county_name       state_name    ##   <chr>     <date>     <dbl> <chr>             <chr>         ## 1 25001     2020-06-01     4 Barnstable County Massachusetts ## 2 25001     2020-06-02     6 Barnstable County Massachusetts ## 3 25001     2020-06-03     5 Barnstable County Massachusetts ## 4 25001     2020-06-04     8 Barnstable County Massachusetts ## 5 25001     2020-06-05     3 Barnstable County Massachusetts ## 6 25001     2020-06-06     4 Barnstable County Massachusetts key(xt) ## [[1]] ## geo_value index(xt) ## time_value interval(xt) ## <interval[1]> ## [1] 1D head(as_tsibble(x, key = \"county_name\")) ## Error in `validate_tsibble()`: ## ! A valid tsibble must have distinct rows identified by key and index. ## ℹ Please use `duplicates()` to check the duplicated rows. head(duplicates(x, key = \"county_name\")) ## # A tibble: 6 × 5 ##   geo_value time_value cases county_name     state_name    ##   <chr>     <date>     <dbl> <chr>           <chr>         ## 1 25009     2020-06-01    63 Essex County    Massachusetts ## 2 25011     2020-06-01     0 Franklin County Massachusetts ## 3 50009     2020-06-01     0 Essex County    Vermont       ## 4 50011     2020-06-01     0 Franklin County Vermont       ## 5 25009     2020-06-02    74 Essex County    Massachusetts ## 6 25011     2020-06-02     0 Franklin County Massachusetts head(as_tsibble(x, key = c(\"county_name\", \"state_name\"))) ## # A tsibble: 6 x 5 [1D] ## # Key:       county_name, state_name [1] ##   geo_value time_value cases county_name    state_name ##   <chr>     <date>     <dbl> <chr>          <chr>      ## 1 50001     2020-06-01     0 Addison County Vermont    ## 2 50001     2020-06-02     0 Addison County Vermont    ## 3 50001     2020-06-03     0 Addison County Vermont    ## 4 50001     2020-06-04     0 Addison County Vermont    ## 5 50001     2020-06-05     0 Addison County Vermont    ## 6 50001     2020-06-06     1 Addison County Vermont"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/aggregation.html","id":"detecting-and-filling-time-gaps","dir":"Articles","previous_headings":"","what":"Detecting and filling time gaps","title":"Aggregate signals over space and time","text":"One major advantages tsibble package ability handle implicit gaps time series data. words, can infer time scale ’re interested (say, daily data), detect apparent gaps (say, values reported January 1 3 January 2). can subsequently use functionality make missing entries explicit, generally help avoid bugs downstream data processing tasks. Let’s first remove certain dates data set create gaps: functions has_gaps(), scan_gaps(), count_gaps() tsibble package provide useful summaries, slightly different formats. can also visualize patterns missingness:  Using fill_gaps() function tsibble, can replace gaps explicit value. default NA, current case, missingness random rather represents small value censored (hypothetical COVID-19 reports, certainly real phenomenon occurs signals), better replace zero, . (approaches, LOCF: last-observation-carried-forward, accomplished first filling NA values following second call tidyr::fill().) Note time series Addison, VT starts August 27, 2020, even though original (uncensored) data set drawn period went back June 6, 2020. setting .full = TRUE, can zero-fill entire span observed (censored) data. Explicit imputation missingness (zero-filling case) can important protecting bugs sorts downstream tasks. example, even something simple 7-day trailing average complicated missingness. function epi_slide() looks rows within window 7 days anchored right reference time point (n = 7 align = \"right\"). days given week missing censored small case counts, taking average observed case counts can misleading unintentionally biased upwards. Meanwhile, running epi_slide() zero-filled data brings trailing averages (appropriately) downwards, can see inspecting Plymouth, MA around July 1, 2021.","code":"# First make geo value more readable for tables, plots, etc. x <- x %>%                 mutate(geo_value = paste(       substr(county_name, 1, nchar(county_name) - 7),       name_to_abbr(state_name), sep = \", \")) %>%      select(geo_value, time_value, cases)  xt <- as_tsibble(x) %>% filter(cases >= 3) head(has_gaps(xt)) ## # A tibble: 6 × 2 ##   geo_value      .gaps ##   <chr>          <lgl> ## 1 Addison, VT    TRUE  ## 2 Barnstable, MA TRUE  ## 3 Bennington, VT TRUE  ## 4 Berkshire, MA  TRUE  ## 5 Bristol, MA    TRUE  ## 6 Caledonia, VT  TRUE head(scan_gaps(xt)) ## # A tsibble: 6 x 2 [1D] ## # Key:       geo_value [1] ##   geo_value   time_value ##   <chr>       <date>     ## 1 Addison, VT 2020-08-28 ## 2 Addison, VT 2020-08-29 ## 3 Addison, VT 2020-08-30 ## 4 Addison, VT 2020-08-31 ## 5 Addison, VT 2020-09-01 ## 6 Addison, VT 2020-09-02 head(count_gaps(xt)) ## # A tibble: 6 × 4 ##   geo_value   .from      .to           .n ##   <chr>       <date>     <date>     <int> ## 1 Addison, VT 2020-08-28 2020-10-04    38 ## 2 Addison, VT 2020-10-06 2020-10-23    18 ## 3 Addison, VT 2020-10-25 2020-11-04    11 ## 4 Addison, VT 2020-11-06 2020-11-10     5 ## 5 Addison, VT 2020-11-14 2020-11-18     5 ## 6 Addison, VT 2020-11-20 2020-11-20     1 library(ggplot2) theme_set(theme_bw())  ggplot(count_gaps(xt),         aes(x = reorder(geo_value, desc(geo_value)),            color = geo_value)) +   geom_linerange(aes(ymin = .from, ymax = .to)) +    geom_point(aes(y = .from)) +   geom_point(aes(y = .to)) +    coord_flip() +    labs(x = \"County\", y = \"Date\") +    theme(legend.position = \"none\") fill_gaps(xt, cases = 0) %>%   head() ## # A tsibble: 6 x 3 [1D] ## # Key:       geo_value [1] ##   geo_value   time_value cases ##   <chr>       <date>     <dbl> ## 1 Addison, VT 2020-08-27     3 ## 2 Addison, VT 2020-08-28     0 ## 3 Addison, VT 2020-08-29     0 ## 4 Addison, VT 2020-08-30     0 ## 5 Addison, VT 2020-08-31     0 ## 6 Addison, VT 2020-09-01     0 xt_filled <- fill_gaps(xt, cases = 0, .full = TRUE)     head(xt_filled) ## # A tsibble: 6 x 3 [1D] ## # Key:       geo_value [1] ##   geo_value   time_value cases ##   <chr>       <date>     <dbl> ## 1 Addison, VT 2020-06-01     0 ## 2 Addison, VT 2020-06-02     0 ## 3 Addison, VT 2020-06-03     0 ## 4 Addison, VT 2020-06-04     0 ## 5 Addison, VT 2020-06-05     0 ## 6 Addison, VT 2020-06-06     0 xt %>%    as_epi_df() %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), n = 7) %>%   filter(geo_value == \"Plymouth, MA\",          abs(time_value - as.Date(\"2021-07-01\")) <= 3) %>%   print(n = 7) ## An `epi_df` object, with metadata: ## * geo_type  = nation ## * time_type = day ## * as_of     = 2022-05-25 21:19:50 ##  ## # A tibble: 4 × 4 ## # Groups:   geo_value [1] ##   geo_value    time_value cases cases_7dav ## * <chr>        <date>     <dbl>      <dbl> ## 1 Plymouth, MA 2021-06-28     3       4.25 ## 2 Plymouth, MA 2021-06-30     7       5    ## 3 Plymouth, MA 2021-07-01     6       5    ## 4 Plymouth, MA 2021-07-02     6       5.2 xt_filled %>%    as_epi_df() %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), n = 7) %>%   filter(geo_value == \"Plymouth, MA\",          abs(time_value - as.Date(\"2021-07-01\")) <= 3) %>%   print(n = 7) ## An `epi_df` object, with metadata: ## * geo_type  = nation ## * time_type = day ## * as_of     = 2022-05-25 21:19:51 ##  ## # A tibble: 7 × 4 ## # Groups:   geo_value [1] ##   geo_value    time_value cases cases_7dav ## * <chr>        <date>     <dbl>      <dbl> ## 1 Plymouth, MA 2021-06-28     3       2.43 ## 2 Plymouth, MA 2021-06-29     0       2.43 ## 3 Plymouth, MA 2021-06-30     7       2.86 ## 4 Plymouth, MA 2021-07-01     6       2.86 ## 5 Plymouth, MA 2021-07-02     6       3.71 ## 6 Plymouth, MA 2021-07-03     0       3.71 ## 7 Plymouth, MA 2021-07-04     0       3.14"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/aggregation.html","id":"aggregate-to-different-time-scales","dir":"Articles","previous_headings":"","what":"Aggregate to different time scales","title":"Aggregate signals over space and time","text":"Continuing useful tsibble functionality, can aggregate different time scales using index_by() tsibble, modifies index variable given object applying suitable time-coarsening transformation (say, moving days weeks, weeks months, ). common use case follow call dplyr verb like summarize() order perform kind aggregation measured variables new index variable. , use functions yearweek() yearmonth() provided tsibble package order aggregate weekly monthly resolutions. former call, set week_start = 7 coincide CDC definition epiweek (epidemiological week).","code":"# Aggregate to weekly xt_filled_week <- xt_filled %>%   index_by(epiweek = ~ yearweek(., week_start = 7)) %>%   group_by(geo_value) %>%    summarize(cases = sum(cases, na.rm = TRUE))  head(xt_filled_week) ## # A tsibble: 6 x 3 [1W] ## # Key:       geo_value [1] ##   geo_value    epiweek cases ##   <chr>         <week> <dbl> ## 1 Addison, VT 2020 W23     0 ## 2 Addison, VT 2020 W24     0 ## 3 Addison, VT 2020 W25     0 ## 4 Addison, VT 2020 W26     0 ## 5 Addison, VT 2020 W27     0 ## 6 Addison, VT 2020 W28     0 # Aggregate to monthly xt_filled_month <- xt_filled_week %>%   index_by(month = ~ yearmonth(.)) %>%   group_by(geo_value) %>%    summarize(cases = sum(cases, na.rm = TRUE))   head(xt_filled_month) ## # A tsibble: 6 x 3 [1M] ## # Key:       geo_value [1] ##   geo_value      month cases ##   <chr>          <mth> <dbl> ## 1 Addison, VT 2020 May     0 ## 2 Addison, VT 2020 Jun     0 ## 3 Addison, VT 2020 Jul     0 ## 4 Addison, VT 2020 Aug     3 ## 5 Addison, VT 2020 Sep     0 ## 6 Addison, VT 2020 Oct    29"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/aggregation.html","id":"geographic-aggregation","dir":"Articles","previous_headings":"","what":"Geographic aggregation","title":"Aggregate signals over space and time","text":"TODO","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/aggregation.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Aggregate signals over space and time","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"getting-data-into-epi_archive-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_archive format","title":"Work with archive objects and data revisions","text":"epi_archive object can constructed data frame, data table, tibble, provided (least) following columns: geo_value: geographic value associated row measurements. time_value: time value associated row measurements. version: time value specifying version row measurements. example, given row version January 15, 2022 time_value January 14, 2022, row contains measurements data January 14, 2022 available one day later. can see , data frame returned delphi.epidata::covidcast() columns required epi_archive format, issue playing role version. can now use as_epi_archive() bring epi_archive format. epi_archive special kind class called R6 class. primary field data table DT, class data.table (data.table package), columns geo_value, time_value, version, well number additional columns. variables geo_value, time_value, version serve key variables data table, well specified metadata (described ). can single row per unique combination key variables, therefore key variables critical figuring generate snapshot data archive, given version (also described ). general, last observation carried forward (LOCF) used data recorded versions. word caution: R6 objects, unlike objects R, reference semantics. important consequence objects copied modified. make copy, can use clone() method R6 class, y <- x$clone(). can read reference semantics Hadley Wickham’s Advanced R book.","code":"x <- dv %>%   select(geo_value, time_value, version = issue, percent_cli = value) %>%   as_epi_archive()  class(x) print(x) ## [1] \"epi_archive\" \"R6\" ## An `epi_archive` object, with metadata: ## * geo_type  = state ## * time_type = day ## ---------- ## * min time value = 2020-06-01 ## * max time value = 2021-11-30 ## * min version    = 2020-06-02 ## * max version    = 2021-12-01 ## ---------- ## Data archive (stored in DT field): 129638 x 4 ## ---------- ## Public methods: initialize, print, as_of, merge, slide, clone class(x$DT) ## [1] \"data.table\" \"data.frame\" head(x$DT) ##    geo_value time_value    version percent_cli ## 1:        ca 2020-06-01 2020-06-02          NA ## 2:        ca 2020-06-01 2020-06-06    2.140116 ## 3:        ca 2020-06-01 2020-06-07    2.140116 ## 4:        ca 2020-06-01 2020-06-08    2.140379 ## 5:        ca 2020-06-01 2020-06-09    2.114430 ## 6:        ca 2020-06-01 2020-06-10    2.133677 key(x$DT) ## [1] \"geo_value\"  \"time_value\" \"version\" original_value <- x$DT$percent_cli[1] y <- x # This DOES NOT make a copy of x y$DT$percent_cli[1] = 0 head(y$DT) ##    geo_value time_value    version percent_cli ## 1:        ca 2020-06-01 2020-06-02    0.000000 ## 2:        ca 2020-06-01 2020-06-06    2.140116 ## 3:        ca 2020-06-01 2020-06-07    2.140116 ## 4:        ca 2020-06-01 2020-06-08    2.140379 ## 5:        ca 2020-06-01 2020-06-09    2.114430 ## 6:        ca 2020-06-01 2020-06-10    2.133677 head(x$DT) ##    geo_value time_value    version percent_cli ## 1:        ca 2020-06-01 2020-06-02    0.000000 ## 2:        ca 2020-06-01 2020-06-06    2.140116 ## 3:        ca 2020-06-01 2020-06-07    2.140116 ## 4:        ca 2020-06-01 2020-06-08    2.140379 ## 5:        ca 2020-06-01 2020-06-09    2.114430 ## 6:        ca 2020-06-01 2020-06-10    2.133677 x$DT$percent_cli[1] <- original_value"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"some-details-on-metadata","dir":"Articles","previous_headings":"","what":"Some details on metadata","title":"Work with archive objects and data revisions","text":"following pieces metadata included fields epi_archive object: geo_type: type geo values. time_type: type time values. additional_metadata: list additional metadata data archive. Metadata epi_archive object x can accessed (altered) directly, x$geo_type x$time_type, etc. Just like as_epi_df(), function as_epi_archive() attempts guess metadata fields epi_archive object instantiated, explicitly specified function call (case ).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"producing-snapshots-in-epi_df-form","dir":"Articles","previous_headings":"","what":"Producing snapshots in epi_df form","title":"Work with archive objects and data revisions","text":"key method epi_archive class as_of(), generates snapshot archive epi_df format. represents --date values signal variables given version. can accessed via x$as_of() epi_archive object x, package also provides simple wrapper function epix_as_of() since likely familiar interface users familiar R6 (object-oriented programming). can see max time value epi_df object x_snapshot generated archive May 29, 2021, even though specified version date June 1, 2021. can infer doctor’s visits signal 2 days latent June 1. Also, can see metadata epi_df object version date recorded as_of field. Using maximum version column underlying data table epi_archive object generates snapshot latest values signal variables entire archive. epix_as_of() function issues warning case, since updates current version may still come later point time, due various reasons, synchronization issues. , pull several snapshots archive, spaced one month apart. overlay corresponding signal curves colored lines, version dates marked dotted vertical lines, draw latest curve black (latest snapshot x_latest archive can provide).  can see interesting highly nontrivial revision behavior: points time provisional data snapshots grossly underestimate latest curve (look particular Florida close end 2021), others overestimate (states towards beginning 2021), though quite dramatically. Modeling revision process, often called backfill modeling, important statistical problem .","code":"x_snapshot <- epix_as_of(x, max_version = as.Date(\"2021-06-01\")) class(x_snapshot) ## [1] \"epi_df\"     \"tbl_df\"     \"tbl\"        \"data.frame\" head(x_snapshot) ## # A tibble: 6 × 3 ##   geo_value time_value percent_cli ##   <chr>     <date>           <dbl> ## 1 ca        2020-06-01        2.75 ## 2 ca        2020-06-02        2.57 ## 3 ca        2020-06-03        2.48 ## 4 ca        2020-06-04        2.41 ## 5 ca        2020-06-05        2.57 ## 6 ca        2020-06-06        2.63 max(x_snapshot$time_value) ## [1] \"2021-05-31\" attributes(x_snapshot)$metadata$as_of ## [1] \"2021-06-01\" x_latest <- epix_as_of(x, max_version = max(x$DT$version)) ## Warning: Getting data as of the latest version possible. For a variety of ## reasons, it is possible that we only have a preliminary picture of this ## version (e.g., the upstream source has updated it but we have not seen it due ## to latency in synchronization). Thus, the snapshot that we produce here might ## not be reproducible at a later time (e.g., when the archive has caught up in ## terms of synchronization). library(purrr) ##  ## Attaching package: 'purrr' ## The following object is masked from 'package:data.table': ##  ##     transpose library(ggplot2) theme_set(theme_bw())  self_max = max(x$DT$version) versions = seq(as.Date(\"2020-06-01\"), self_max - 1, by = \"1 month\") snapshots <- map_dfr(versions, function(v) {    epix_as_of(x, max_version = v) %>% mutate(version = v) }) %>%   bind_rows(x_latest %>% mutate(version = self_max)) %>%   mutate(latest = version == self_max)  ggplot(snapshots %>% filter(!latest),             aes(x = time_value, y = percent_cli)) +     geom_line(aes(color = factor(version))) +    geom_vline(aes(color = factor(version), xintercept = version), lty = 2) +   facet_wrap(~ geo_value, scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"% of doctor's visits with CLI\") +    theme(legend.position = \"none\") +   geom_line(data = snapshots %>% filter(latest),                aes(x = time_value, y = percent_cli),                 inherit.aes = FALSE, color = \"black\") ## Warning: Removed 53 row(s) containing missing values (geom_path). ## Warning: Removed 4 row(s) containing missing values (geom_path)."},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"merging-epi_archive-objects","dir":"Articles","previous_headings":"","what":"Merging epi_archive objects","title":"Work with archive objects and data revisions","text":"Now demonstrate merge underlying data tables two epi_archive objects together. epi_archive class provides method merge() precisely purpose. wrapper function called epix_merge(); , just offered matter convenience/familiarity users. merge working epi_archive versioned percentage CLI outpatient visits another one versioned COVID-19 case reporting data, fetch COVIDcast API, rate scale (counts per 100,000 people population). merging archives, typically want perform full join, otherwise throwing versioned data one table . accomplished setting = TRUE call epix_merge(). Furthermore, function provides option filling NA values via LOCF setting locf = TRUE. general, unless two data tables exact pattern updates, get NA values signals performing full join. original data archives stored LOCF (last observation carried forward) format first place, generally makes sense perform NA filling merging using LOCF. Therefore locf = TRUE default. Importantly, can see, way epix_merge() works overwrites data table first epi_archive object x merged data table.","code":"y <- covidcast(   data_source = \"jhu-csse\",   signals = \"confirmed_7dav_incidence_prop\",   time_type = \"day\",   geo_type = \"state\",   time_value = epirange(20200601, 20211201),   geo_values = \"ca,fl,ny,tx\",   issues = epirange(20200601, 20211201) ) %>%   fetch_tbl() %>%   select(geo_value, time_value, version = issue, case_rate_7d_av = value) %>%   as_epi_archive()  epix_merge(x, y, all = TRUE) print(x) head(x$DT) ## An `epi_archive` object, with metadata: ## * geo_type  = state ## * time_type = day ## ---------- ## * min time value = 2020-06-01 ## * max time value = 2021-11-30 ## * min version    = 2020-06-02 ## * max version    = 2021-12-01 ## ---------- ## Data archive (stored in DT field): 129638 x 5 ## ---------- ## Public methods: initialize, print, as_of, merge, slide, clone ##    geo_value time_value    version percent_cli case_rate_7d_av ## 1:        ca 2020-06-01 2020-06-02          NA        6.628329 ## 2:        ca 2020-06-01 2020-06-06    2.140116        6.628329 ## 3:        ca 2020-06-01 2020-06-07    2.140116        6.628329 ## 4:        ca 2020-06-01 2020-06-08    2.140379        6.628329 ## 5:        ca 2020-06-01 2020-06-09    2.114430        6.628329 ## 6:        ca 2020-06-01 2020-06-10    2.133677        6.628329"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"sliding-version-aware-computations","dir":"Articles","previous_headings":"","what":"Sliding version-aware computations","title":"Work with archive objects and data revisions","text":"Lastly, demonstrate another key method epi_archive class, slide() method. works just like epi_slide() epi_df object, one key difference: performs version-aware computations. , computation given reference time t, uses data available t. wrapper function called epix_slide(); , just convenience/familiarity—interface purposely designed mirror epi_slide() epi_df objects. demonstration, ’ll revisit forecasting example slide vignette, now ’ll build forecaster uses properly-versioned data (available real-time) forecast future COVID-19 case rates current past COVID-19 case rates, well current past values outpatient CLI signal medical claims. ’ll extend prob_ar() function slide vignette accomodate exogenous variables autoregressive model, often referred ARX model. Next slide forecaster working epi_archive object, order forecast COVID-19 case rates 7 days future. get back tibble z grouping variables (geo value), time values, three columns fc_point, fc_lower, fc_upper produced slide computation correspond point forecast, lower upper endpoints 95% prediction band, respectively. (instead set as_list_col = TRUE call epix_slide(), gotten list column fc, element fc data frame named columns point, lower, upper.) whole, epix_slide() works similarly epix_slide(), though notable differences, even apart version-aware aspect. can read documentation epix_slide() details. finish comparing version-aware -unaware forecasts various points time forecast horizons. former comes applying epix_slide() epi_archive object x, latter applying epi_slide() latest snapshot data x_latest.  row displays forecasts different location (CA FL), column corresponds whether properly-versioned data used (FALSE means , TRUE means yes). can see properly-versioned forecaster , points time, problematic; example, massively overpredicts peak locations winter wave 2020. However, performance pretty poor across board , whether properly-versioned data used. Similar saw slide vignette, ARX forecasts can volatile, overconfident, . volatility can attenuated training ARX model jointly locations; advanced sliding vignette gives demonstration . really, epipredict package, builds data structures functionality current package, place look robust forecasting methodology. forecasters appear vignettes current package meant demo slide functionality basic forecasting methodology possible.","code":"prob_arx <- function(x, y, lags = c(0, 7, 14), ahead = 7, min_train_window = 20,                      lower_level = 0.05, upper_level = 0.95, symmetrize = TRUE,                       intercept = FALSE, nonneg = TRUE) {      # Return NA if insufficient training data   if (length(y) < min_train_window + max(lags) + ahead) {     return(data.frame(point = NA, lower = NA, upper = NA))   }      # Useful transformations   if (!missing(x)) x <- data.frame(x, y)   else x <- data.frame(y)   if (!is.list(lags)) lags <- list(lags)   lags = rep(lags, length.out = ncol(x))      # Build features and response for the AR model, and then fit it   dat <- do.call(     data.frame,      unlist( # Below we loop through and build the lagged features       purrr::map(1:ncol(x), function(i) {          purrr::map(lags[[i]], function(j) lag(x[,i], n = j))       }),       recursive = FALSE))   names(dat) = paste0(\"x\", 1:ncol(dat))   if (intercept) dat$x0 = rep(1, nrow(dat))   dat$y <- lead(y, n = ahead)    obj <- lm(y ~ . + 0, data = dat)      # Use LOCF to fill NAs in the latest feature values, make a prediction   setDT(dat)    setnafill(dat, type = \"locf\")   point <- predict(obj, newdata = tail(dat, 1))      # Compute a band    r <- residuals(obj)   s <- ifelse(symmetrize, -1, NA) # Should the residuals be symmetrized?   q <- quantile(c(r, s * r), probs = c(lower_level, upper_level), na.rm = TRUE)   lower <- point + q[1]   upper <- point + q[2]      # Clip at zero if we need to, then return   if (nonneg) {      point = max(point, 0)      lower = max(lower, 0)      upper = max(upper, 0)    }   return(data.frame(point = point, lower = lower, upper = upper)) } fc_time_values <- seq(as.Date(\"2020-08-01\"),                        as.Date(\"2021-12-01\"),                        by = \"1 month\")  z <- epix_slide(x, fc = prob_arx(x = percent_cli, y = case_rate_7d_av), n = 120,                  ref_time_values = fc_time_values, group_by = geo_value)  head(z, 10) ## # A tibble: 10 × 5 ##    geo_value time_value fc_point fc_lower fc_upper ##    <chr>     <date>        <dbl>    <dbl>    <dbl> ##  1 ca        2020-08-01    21.0     19.1     23.0  ##  2 fl        2020-08-01    44.5     38.9     50.0  ##  3 ny        2020-08-01     3.10     2.89     3.31 ##  4 tx        2020-08-01    35.5     33.6     37.4  ##  5 ca        2020-09-01    22.9     20.1     25.8  ##  6 fl        2020-09-01    15.5     10.5     20.6  ##  7 ny        2020-09-01     3.16     2.93     3.39 ##  8 tx        2020-09-01    17.5     14.3     20.7  ##  9 ca        2020-10-01    12.8      9.21    16.5  ## 10 fl        2020-10-01    14.7      8.72    20.6 x_latest <- epix_as_of(x, max_version = max(x$DT$version))  # Simple function to produce forecasts k weeks ahead k_week_ahead <- function(x, ahead = 7, as_of = TRUE) {   if (as_of) {     x %>%       epix_slide(fc = prob_arx(percent_cli, case_rate_7d_av, ahead = ahead), n = 120,                  ref_time_values = fc_time_values, group_by = geo_value) %>%       mutate(target_date = time_value + ahead, as_of = TRUE)    }   else {     x_latest %>%        group_by(geo_value) %>%       epi_slide(fc = prob_arx(percent_cli, case_rate_7d_av, ahead = ahead), n = 120,                 ref_time_values = fc_time_values) %>%       mutate(target_date = time_value + ahead, as_of = FALSE)    } }  # Generate the forecasts, and bind them together fc <- bind_rows(k_week_ahead(x, ahead = 7, as_of = TRUE),                 k_week_ahead(x, ahead = 14, as_of = TRUE),                 k_week_ahead(x, ahead = 21, as_of = TRUE),                 k_week_ahead(x, ahead = 28, as_of = TRUE),                 k_week_ahead(x, ahead = 7, as_of = FALSE),                 k_week_ahead(x, ahead = 14, as_of = FALSE),                 k_week_ahead(x, ahead = 21, as_of = FALSE),                 k_week_ahead(x, ahead = 28, as_of = FALSE))  # Plot them, on top of latest COVID-19 case rates  ggplot(fc, aes(x = target_date, group = time_value, fill = as_of)) +   geom_ribbon(aes(ymin = fc_lower, ymax = fc_upper), alpha = 0.4) +   geom_line(data = x_latest, aes(x = time_value, y = case_rate_7d_av),                 inherit.aes = FALSE, color = \"gray50\") +   geom_line(aes(y = fc_point)) + geom_point(aes(y = fc_point), size = 0.5) +    geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +   facet_grid(vars(geo_value), vars(as_of), scales = \"free\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +    theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/archive.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Work with archive objects and data revisions","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidatab Doctor’s Visit API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/correlation.html","id":"correlations-grouped-by-time","dir":"Articles","previous_headings":"","what":"Correlations grouped by time","title":"Correlate signals over space and time","text":"epi_cor() function operates epi_df object, requires specification variables correlate, next two arguments (var1 var2). general, can specify grouping variable (combination variables) correlation computations call epi_cor(), via cor_by argument. potentially leads many ways compute correlations. always least two ways compute correlations epi_df: grouping time value, geo value. former obtained via cor_by = time_value.  plot addresses question: “given day, case death rates linearly associated, across U.S. states?”. might interested broadening question, instead asking: “given day, higher case rates tend associate higher death rates?”, removing dependence linear relationship. latter can addressed using Spearman correlation, accomplished setting method = \"spearman\" call epi_cor(). Spearman correlation highly robust invariant monotone transformations.","code":"library(ggplot2) theme_set(theme_bw())  z1 <- epi_cor(x, case_rate, death_rate, cor_by = \"time_value\")  ggplot(z1, aes(x = time_value, y = cor)) +    geom_line() +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Correlation\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/correlation.html","id":"lagged-correlations","dir":"Articles","previous_headings":"","what":"Lagged correlations","title":"Correlate signals over space and time","text":"might also interested case rates associate death rates future. Using dt1 parameter epi_cor(), can lag case rates back number days want, calculating correlations. , set dt1 = -10. means var1 = case_rate lagged 10 days, case rates June 1st correlated death rates June 11th. (might also help think way: death rates certain day correlated case rates offset -10 days.)  Note epi_cor() takes argument shift_by determines grouping use time shifts. default geo_value, makes sense problem hand (another setting, may want group geo value another variable—say, age—time shifting). can see , generally, lagging case rates back 10 days improves correlations, confirming case rates better correlated death rates 10 days now.","code":"z2 <- epi_cor(x, case_rate, death_rate, cor_by = time_value, dt1 = -10)  z <- rbind(z1 %>% mutate(lag = 0),             z2 %>% mutate(lag = 10)) %>%   mutate(lag = as.factor(lag))  ggplot(z, aes(x = time_value, y = cor)) +   geom_line(aes(color = lag)) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Correlation\", col = \"Lag\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/correlation.html","id":"correlations-grouped-by-state","dir":"Articles","previous_headings":"","what":"Correlations grouped by state","title":"Correlate signals over space and time","text":"second option group geo value, obtained setting cor_by = geo_value. ’ll look correlations 0- 10-day lagged case rates.  can see , generally speaking, lagging case rates back 10 days improves correlations.","code":"z1 <- epi_cor(x, case_rate, death_rate, cor_by = geo_value) z2 <- epi_cor(x, case_rate, death_rate, cor_by = geo_value, dt1 = -10)  z <- rbind(z1 %>% mutate(lag = 0),             z2 %>% mutate(lag = 10)) %>%   mutate(lag = as.factor(lag))  ggplot(z, aes(cor)) +   geom_density(aes(fill = lag, col = lag), alpha = 0.5) +   labs(x = \"Correlation\", y = \"Density\", fill = \"Lag\", col = \"Lag\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/correlation.html","id":"more-systematic-lag-analysis","dir":"Articles","previous_headings":"","what":"More systematic lag analysis","title":"Correlate signals over space and time","text":"Next perform systematic investigation correlations broad range lag values.  can see pretty clear curvature mean correlation case death rates (correlations come grouping geo value) function lag. maximum occurs lag somewhere around 18 days.","code":"library(purrr) lags = 0:35  z <- map_dfr(lags, function(lag) {   epi_cor(x, case_rate, death_rate, cor_by = geo_value, dt1 = -lag) %>%      mutate(lag = lag)    })  z %>%   group_by(lag) %>%   summarize(mean = mean(cor, na.rm = TRUE)) %>%   ggplot(aes(x = lag, y = mean)) +    geom_line() + geom_point() +   labs(x = \"Lag\", y = \"Mean correlation\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/correlation.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Correlate signals over space and time","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/epiprocess.html","id":"installing","dir":"Articles","previous_headings":"","what":"Installing","title":"Get started with `epiprocess`","text":"package CRAN yet, can installed using devtools package: Building vignettes, getting started guide, takes significant amount time. included package default. want include vignettes, use modified command:","code":"devtools::install_github(\"cmu-delphi/epiprocess\", ref = \"main\") devtools::install_github(\"cmu-delphi/epiprocess\", ref = \"main\",                          build_vignettes = TRUE, dependencies = TRUE)"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/epiprocess.html","id":"getting-data-into-epi_df-format","dir":"Articles","previous_headings":"","what":"Getting data into epi_df format","title":"Get started with `epiprocess`","text":"’ll start showing get data epi_df format, just tibble bit special structure, format assumed functions epiprocess package. epi_df object (least) following columns: geo_value: geographic value associated row measurements. time_value: time value associated row measurements. can number columns can serve measured variables, also broadly refer signal variables. documentation gives details data format. data frame tibble geo_value time_value columns can converted epi_df object, using function as_epi_df(). example, ’ll work daily cumulative COVID-19 cases four U.S. states: CA, FL, NY, TX, time span mid 2020 early 2022, ’ll use delphi.epidata package fetch data COVIDcast API. can see, data frame returned delphi.epidata::covidcast() columns required epi_df object (along many others). can use as_epi_df(), specification relevant metadata, bring data frame epi_df format.","code":"library(delphi.epidata) library(epiprocess) library(dplyr)  cases <- covidcast(   data_source = \"jhu-csse\",   signals = \"confirmed_cumulative_num\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20200301, 20220131),   geo_values = \"ca,fl,ny,tx\" ) %>% fetch_tbl()  colnames(cases) ##  [1] \"geo_value\"           \"signal\"              \"source\"              ##  [4] \"geo_type\"            \"time_type\"           \"time_value\"          ##  [7] \"direction\"           \"issue\"               \"lag\"                 ## [10] \"missing_value\"       \"missing_stderr\"      \"missing_sample_size\" ## [13] \"value\"               \"stderr\"              \"sample_size\" x <- as_epi_df(cases,                 geo_type = \"state\",                time_type = \"day\",                as_of = max(cases$issue)) %>%   select(geo_value, time_value, total_cases = value)  class(x) ## [1] \"epi_df\"     \"tbl_df\"     \"tbl\"        \"data.frame\" summary(x) ## An `epi_df` x, with metadata: ## * geo_type  = state ## * time_type = day ## * as_of     = 2022-05-25 ## ---------- ## * min time value              = 2020-03-01 ## * max time value              = 2022-01-31 ## * average rows per time value = 4 head(x) ## # A tibble: 6 × 3 ##   geo_value time_value total_cases ##   <chr>     <date>           <dbl> ## 1 ca        2020-03-01          19 ## 2 fl        2020-03-01           0 ## 3 ny        2020-03-01           0 ## 4 tx        2020-03-01           0 ## 5 ca        2020-03-02          23 ## 6 fl        2020-03-02           1 attributes(x)$metadata ## $geo_type ## [1] \"state\" ##  ## $time_type ## [1] \"day\" ##  ## $as_of ## [1] \"2022-05-25\""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/epiprocess.html","id":"some-details-on-metadata","dir":"Articles","previous_headings":"","what":"Some details on metadata","title":"Get started with `epiprocess`","text":"general, epi_df object following fields metadata: geo_type: type geo values. time_type: type time values. as_of: time value given data available. Metadata epi_df object x can accessed (altered) via attributes(x)$metadata. first two fields , geo_type time_type, currently used downstream functions epiprocess package, serve useful bits information convey data set hand. last field , as_of, one unique aspects epi_df object. brief, can think epi_df object single snapshot data set contains --date values signals interest, time specified as_of. example, as_of January 31, 2022, epi_df object --date version data available January 31, 2022. epiprocess package also provides companion data structure called epi_archive, stores full version history given data set. See archive vignette . geo_type, time_type, as_of arguments missing call as_epi_df(), function try infer passed object. Usually, geo_type time_type can inferred geo_value time_value columns, respectively, inferring as_of field easy. See documentation as_epi_df() details.","code":"x <- as_epi_df(cases) %>%   select(geo_value, time_value, total_cases = value)  attributes(x)$metadata ## $geo_type ## [1] \"state\" ##  ## $time_type ## [1] \"day\" ##  ## $as_of ## [1] \"2022-05-25\""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/epiprocess.html","id":"working-with-epi_df-objects-downstream","dir":"Articles","previous_headings":"","what":"Working with epi_df objects downstream","title":"Get started with `epiprocess`","text":"Data epi_df format easy work downstream, since standard tabular data format; vignettes, ’ll walk basic signal processing tasks using functions provided epiprocess package. course, can also write custom code downstream uses, like plotting, pretty easy ggplot2.  last couple examples, ’ll look data sets just show might get epi_df format. Data daily new (cumulative) SARS cases Canada 2003, outbreaks package:  Data new cases Ebola Sierra Leone 2014, package:","code":"library(ggplot2) theme_set(theme_bw())  ggplot(x, aes(x = time_value, y = total_cases, color = geo_value)) +    geom_line() +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Cumulative COVID-19 cases\", color = \"State\") x <- outbreaks::sars_canada_2003 %>%   mutate(geo_value = \"ca\") %>%   select(geo_value, time_value = date, starts_with(\"cases\")) %>%   as_epi_df(geo_type = \"nation\")  head(x) ## # A tibble: 6 × 6 ##   geo_value time_value cases_travel cases_household cases_healthcare cases_other ##   <chr>     <date>            <int>           <int>            <int>       <int> ## 1 ca        2003-02-23            1               0                0           0 ## 2 ca        2003-02-24            0               0                0           0 ## 3 ca        2003-02-25            0               0                0           0 ## 4 ca        2003-02-26            0               1                0           0 ## 5 ca        2003-02-27            0               0                0           0 ## 6 ca        2003-02-28            1               0                0           0 library(tidyr) x <- x %>%    pivot_longer(starts_with(\"cases\"), names_to = \"type\") %>%   mutate(type = substring(type, 7))  yrange <- range(x %>% group_by(time_value) %>%                    summarize(value = sum(value)) %>% pull(value))  ggplot(x, aes(x = time_value, y = value)) +   geom_col(aes(fill = type)) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   scale_y_continuous(breaks = yrange[1]:yrange[2]) +   labs(x = \"Date\", y = \"SARS cases in Canada\", fill = \"Type\") x <- outbreaks::ebola_sierraleone_2014 %>%   mutate(     cases = ifelse(status == \"confirmed\", 1, 0),     province = case_when(       district %in% c(\"Kailahun\", \"Kenema\", \"Kono\") ~ \"Eastern\",       district %in% c(\"Bombali\", \"Kambia\", \"Koinadugu\",                       \"Port Loko\", \"Tonkolili\") ~ \"Northern\",       district %in% c(\"Bo\", \"Bonthe\", \"Moyamba\", \"Pujehun\") ~ \"Sourthern\",       district %in% c(\"Western Rural\", \"Western Urban\") ~ \"Western\")) %>%    select(geo_value = province,          time_value = date_of_onset,          cases) %>% filter(cases==1) %>%   group_by(geo_value, time_value) %>%    summarise(cases = sum(cases)) %>%   as_epi_df(geo_type=\"province\")  ggplot(x, aes(x = time_value, y = cases)) +    geom_col(aes(fill = geo_value), show.legend = FALSE) +    facet_wrap(~ geo_value, scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Confirmed cases of Ebola in Sierra Leone\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"growth-rate-basics","dir":"Articles","previous_headings":"","what":"Growth rate basics","title":"Estimate growth rates in signals","text":"growth rate function \\(f\\) defined continuously-valued parameter \\(t\\) defined \\(f'(t)/f(t)\\), \\(f'(t)\\) derivative \\(f\\) \\(t\\). estimate growth rate signal discrete-time (can thought evaluations discretizations underlying function continuous-time), can estimate derivative divide signal value (possibly smoothed version signal value). growth_rate() function takes sequence underlying design points x corresponding sequence y signal values, allows us choose following methods estimating growth rate given reference point x0, setting method argument: “rel_change”: uses \\((\\bar B/\\bar - 1) / h\\), \\(\\bar B\\) average y second half sliding window bandwidth h centered reference point x0, \\(\\bar \\) average first half. can seen using first-difference approximation derivative. “linear_reg”: uses slope linear regression y x sliding window centered reference point x0, divided fitted value linear regression x0. “smooth_spline”: uses estimated derivative x0 smoothing spline fit x y, via stats::smooth.spline(), divided fitted value spline x0. “trend_filter”: uses estimated derivative x0 polynomial trend filtering (discrete spline) fit x y, via genlasso::trendfilter(), divided fitted value discrete spline x0. default growth_rate() x0 = x, returns estimate growth rate underlying design point.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"relative-change","dir":"Articles","previous_headings":"","what":"Relative change","title":"Estimate growth rates in signals","text":"default method “rel_change”, simplest way estimate growth rates. default bandwidth h = 7, daily data, considers relative change signal adjacent weeks. can wrap growth_rate() call dplyr::mutate() append new column epi_df object computed growth rates. can visualize growth rate estimates plotting signal values highlighting periods time relative change 1% (red) -1% (blue), faceting geo value.  direct visualization, plot estimated growth rates , overlaying curves two states one plot.  can see estimated growth rates relative change method somewhat volatile, appears bias towards towards right boundary time span—look estimated growth rate Georgia late December 2021, takes potentially suspicious dip. general, estimation derivatives difficult near boundary, relative changes can suffer particularly noticeable boundary bias based difference averages two halves local window, simplistic approach, one halves truncated near boundary.","code":"x <- x %>%    group_by(geo_value) %>%    mutate(cases_gr1 = growth_rate(time_value, cases))  head(x, 10) ## # A tibble: 10 × 4 ##    geo_value time_value cases cases_gr1 ##    <chr>     <date>     <dbl>     <dbl> ##  1 ga        2020-06-01  643.   0.00601 ##  2 ga        2020-06-02  603.   0.0185  ##  3 ga        2020-06-03  608    0.0240  ##  4 ga        2020-06-04  656.   0.0218  ##  5 ga        2020-06-05  677.   0.0193  ##  6 ga        2020-06-06  718.   0.0163  ##  7 ga        2020-06-07  691.   0.0180  ##  8 ga        2020-06-08  656.   0.0234  ##  9 ga        2020-06-09  720.   0.0227  ## 10 ga        2020-06-10  727.   0.0227 library(ggplot2) theme_set(theme_bw())  upper = 0.01 lower = -0.01  ggplot(x, aes(x = time_value, y = cases)) +    geom_tile(data = x %>% filter(cases_gr1 >= upper),             aes(x = time_value, y = 0, width = 7, height = Inf),              fill = 2, alpha = 0.08) +    geom_tile(data = x %>% filter(cases_gr1 <= lower),             aes(x = time_value, y = 0, width = 7, height = Inf),              fill = 4, alpha = 0.08) +     geom_line() +      facet_wrap(vars(geo_value), scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 cases\") ggplot(x, aes(x = time_value, y = cases_gr1)) +    geom_line(aes(col = geo_value)) +    geom_hline(yintercept = upper, linetype = 2, col = 2) +   geom_hline(yintercept = lower, linetype = 2, col = 4) +   scale_color_manual(values = c(3,6)) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"State\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"linear-regression","dir":"Articles","previous_headings":"","what":"Linear regression","title":"Estimate growth rates in signals","text":"second simplest method available “linear_reg”, whose default bandwidth h = 7. Compared “rel_change”, appears behave similarly overall, thankfully avoids troublesome spikes:","code":"x <- x %>%    group_by(geo_value) %>%    mutate(cases_gr2 = growth_rate(time_value, cases, method = \"linear_reg\"))  x %>%   pivot_longer(cols = starts_with(\"cases_gr\"),                names_to = \"method\",                 values_to = \"gr\") %>%   mutate(method = recode(method,                          cases_gr1 = \"rel_change\",                          cases_gr2 = \"linear_reg\")) %>%   ggplot(aes(x = time_value, y = gr)) +    geom_line(aes(col = method)) +    scale_color_manual(values = c(2,4)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"nonparametric-estimation","dir":"Articles","previous_headings":"","what":"Nonparametric estimation","title":"Estimate growth rates in signals","text":"can also use nonparametric method estimate derivative, “smooth_spline” “trend_filter”. latter going generally computationally expensive, also able adapt better local level smoothness. (apparent efficiency actually compounded particular implementations default settings methods: “trend_filter” based full solution path algorithm provided genlasso package, performs cross-validation default order pick level regularization; read documentation growth_rate() details.)  particular example, trend filtering estimates growth rate appear much stable smoothing spline, also much stable estimates local relative changes linear regressions. smoothing spline growth rate estimates based default settings stats::smooth.spline(), appear severely -regularized . arguments stats::smooth.spline() can customized passing additional arguments ... call growth_rate(); similarly, can also use additional arguments customize settings underlying trend filtering functions genlasso::trendfilter(), genlasso::cv.trendfilter(), documentation growth_rate() gives full details.","code":"x <- x %>%    group_by(geo_value) %>%    mutate(cases_gr3 = growth_rate(time_value, cases, method = \"smooth_spline\"),          cases_gr4 = growth_rate(time_value, cases, method = \"trend_filter\"))  x %>%   select(geo_value, time_value, cases_gr3, cases_gr4) %>%   pivot_longer(cols = starts_with(\"cases_gr\"),                names_to = \"method\",                 values_to = \"gr\") %>%   mutate(method = recode(method,                          cases_gr3 = \"smooth_spline\",                          cases_gr4 = \"trend_filter\")) %>%   ggplot(aes(x = time_value, y = gr)) +    geom_line(aes(col = method)) +    scale_color_manual(values = c(3,6)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"log-scale-estimation","dir":"Articles","previous_headings":"","what":"Log scale estimation","title":"Estimate growth rates in signals","text":"general, alternative view growth rate function \\(f\\) given defining \\(g(t) = \\log(f(t))\\), observing \\(g'(t) = f'(t)/f(t)\\). Therefore, method estimates derivative can simply applied log signal interest, light, method (“rel_change”, “linear_reg”, “smooth_spline”, “trend_filter”) log scale analog, can used setting argument log_scale = TRUE call growth_rate().   Comparing rel_change_log curves rel_change counterparts (shown earlier figures), see former curves appear less volatile match linear regression estimates much closely. particular, rel_change upward spikes, rel_change_log less pronounced spikes. occur? estimate \\(g'(t)\\) can expressed \\(\\mathbb E[\\log(B)-\\log()]/h = \\mathbb E[\\log(1+hR)]/h\\), \\(R = ((B-)/h) / \\), expectation refers averaging \\(h\\) observations window. Consider following two relevant inequalities, due concavity logarithm function: \\[ \\mathbb E[\\log(1+hR)]/h \\leq \\log(1+h\\mathbb E[R])/h \\leq \\mathbb E[R]. \\] first inequality Jensen’s; second inequality tangent line concave function lies . Finally, observe \\(\\mathbb E[R] \\approx ((\\bar B-\\bar )/h) / \\bar \\), rel_change estimate. explains rel_change_log curve often lies rel_change curve.","code":"x <- x %>%    group_by(geo_value) %>%    mutate(cases_gr5 = growth_rate(time_value, cases, method = \"rel_change\",                                   log_scale = TRUE),          cases_gr6 = growth_rate(time_value, cases, method = \"linear_reg\",                                   log_scale = TRUE),          cases_gr7 = growth_rate(time_value, cases, method = \"smooth_spline\",                                   log_scale = TRUE),          cases_gr8 = growth_rate(time_value, cases, method = \"trend_filter\",                                   log_scale = TRUE))  x %>%   select(geo_value, time_value, cases_gr5, cases_gr6) %>%   pivot_longer(cols = starts_with(\"cases_gr\"),                names_to = \"method\",                 values_to = \"gr\") %>%   mutate(method = recode(method,                          cases_gr5 = \"rel_change_log\",                          cases_gr6 = \"linear_reg_log\")) %>%   ggplot(aes(x = time_value, y = gr)) +    geom_line(aes(col = method)) +    scale_color_manual(values = c(2,4)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\") x %>%   select(geo_value, time_value, cases_gr7, cases_gr8) %>%   pivot_longer(cols = starts_with(\"cases_gr\"),                names_to = \"method\",                 values_to = \"gr\") %>%   mutate(method = recode(method,                          cases_gr7 = \"smooth_spline_log\",                          cases_gr8 = \"trend_filter_log\")) %>%   ggplot(aes(x = time_value, y = gr)) +    geom_line(aes(col = method)) +    scale_color_manual(values = c(3,6)) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Growth rate\", col = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/growth_rate.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Estimate growth rates in signals","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/outliers.html","id":"outlier-detection","dir":"Articles","previous_headings":"","what":"Outlier detection","title":"Detect and correct outliers in signals","text":"detect_outlr() function allows us run multiple outlier detection methods given signal, (optionally) combine results methods. , ’ll investigate outlier detection results following methods. Detection based rolling median, using detect_outlr_rm(), computes rolling median default window size n time points centered time point consideration, computes thresholds based multiplier times rolling IQR computed residuals. Detection based seasonal-trend decomposition using LOESS (STL), using detect_outlr_stl(), similar rolling median method replaces rolling median fitted values STL. Detection based STL decomposition, without seasonality term, amounts smoothing using LOESS. outlier detection methods specified using tibble passed detect_outlr(), one row per method, whose columms specify outlier detection function, input arguments (nondefault values need supplied), abbreviated name method used tracking results. Abbreviations “rm” “stl” can used built-detection functions detect_outlr_rm() detect_outlr_stl(), respectively. Additionally, ’ll form combined lower upper thresholds, calculated median lower upper thresholds methods time point. Note using combined median threshold equivalent using majority vote across base methods determine whether value outlier. visualize results, first define convenience function plotting. Now produce plots state time, faceting detection method.","code":"detection_methods = bind_rows(   tibble(method = \"rm\",          args = list(list(detect_negatives = TRUE,                           detection_multiplier = 2.5)),          abbr = \"rm\"),   tibble(method = \"stl\",          args = list(list(detect_negatives = TRUE,                           detection_multiplier = 2.5,                           seasonal_period = 7)),          abbr = \"stl_seasonal\"),   tibble(method = \"stl\",          args = list(list(detect_negatives = TRUE,                           detection_multiplier = 2.5,                           seasonal_period = NULL)),          abbr = \"stl_nonseasonal\"))  detection_methods ## # A tibble: 3 × 3 ##   method args             abbr            ##   <chr>  <list>           <chr>           ## 1 rm     <named list [2]> rm              ## 2 stl    <named list [3]> stl_seasonal    ## 3 stl    <named list [3]> stl_nonseasonal x <- x %>%   group_by(geo_value) %>%   mutate(outlier_info  = detect_outlr(     x = time_value, y = cases,     methods = detection_methods,     combiner = \"median\")) %>%   unnest(outlier_info)  head(x) ## # A tibble: 6 × 15 ##   geo_value time_value cases rm_lower rm_upper rm_replacement stl_seasonal_lower ##   <chr>     <date>     <dbl>    <dbl>    <dbl>          <dbl>              <dbl> ## 1 fl        2020-06-01   667    345      2195             667                 0  ## 2 nj        2020-06-01   486     64.4     926.            486               221. ## 3 fl        2020-06-02   617    406.     2169.            617                 0  ## 4 nj        2020-06-02   658    140.      841.            658               245. ## 5 fl        2020-06-03  1317    468.     2142.           1317                 0  ## 6 nj        2020-06-03   541    216       756             541               227. ## # … with 8 more variables: stl_seasonal_upper <dbl>, ## #   stl_seasonal_replacement <dbl>, stl_nonseasonal_lower <dbl>, ## #   stl_nonseasonal_upper <dbl>, stl_nonseasonal_replacement <dbl>, ## #   combined_lower <dbl>, combined_upper <dbl>, combined_replacement <dbl> # Plot outlier detection bands and/or points identified as outliers plot_outlr <- function(x, signal, method_abbr, bands = TRUE, points = TRUE,                         facet_vars = vars(geo_value), nrow = NULL, ncol = NULL,                        scales = \"fixed\") {   # Convert outlier detection results to long format    signal <- rlang::enquo(signal)   x_long <- x %>%     pivot_longer(       cols = starts_with(method_abbr),       names_to = c(\"method\", \".value\"),       names_pattern = \"(.+)_(.+)\")      # Start of plot with observed data   p <- ggplot() +     geom_line(data = x, mapping = aes(x = time_value, y = !!signal))    # If requested, add bands   if (bands)      p <- p + geom_ribbon(data = x_long,                           aes(x = time_value, ymin = lower, ymax = upper,                               color = method), fill = NA)    # If requested, add points   if (points) {     x_detected <- x_long %>% filter((!!signal < lower) | (!!signal > upper))     p <- p + geom_point(data = x_detected,                          aes(x = time_value, y = !!signal, color = method,                              shape = method))   }    # If requested, add faceting   if (!is.null(facet_vars))      p <- p + facet_wrap(facet_vars, nrow = nrow, ncol = ncol, scales = scales)    return(p) } method_abbr <- c(detection_methods$abbr, \"combined\")  plot_outlr(x %>% filter(geo_value == \"fl\"), cases, method_abbr,            facet_vars = vars(method), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 counts\", color  = \"Method\",        shape = \"Method\") plot_outlr(x %>% filter(geo_value == \"nj\"), cases, method_abbr,            facet_vars = vars(method), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 counts\", color  = \"Method\",        shape = \"Method\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/outliers.html","id":"outlier-correction","dir":"Articles","previous_headings":"","what":"Outlier correction","title":"Detect and correct outliers in signals","text":"Finally, order correct outliers, can use posited replacement values returned outlier detection method. use replacement value combined method, defined median replacement values base methods time point.  advanced correction functionality coming point future.","code":"y <- x %>%    mutate(cases_corrected = combined_replacement) %>%   select(geo_value, time_value, cases, cases_corrected)   y %>% filter(cases != cases_corrected) ## # A tibble: 22 × 4 ## # Groups:   geo_value [2] ##    geo_value time_value cases cases_corrected ##    <chr>     <date>     <dbl>           <dbl> ##  1 fl        2020-07-12 15300          10181  ##  2 nj        2020-07-19    -8            320. ##  3 nj        2020-08-13   694            404. ##  4 nj        2020-08-14   619            397. ##  5 nj        2020-08-16    40            366  ##  6 nj        2020-08-22   555            360  ##  7 fl        2020-09-01  7569           2861. ##  8 nj        2020-10-08  1415            873. ##  9 fl        2020-10-10     0           2660  ## 10 fl        2020-10-11  5570           2660  ## # … with 12 more rows ggplot(y, aes(x = time_value)) +   geom_line(aes(y = cases), linetype = 2) +   geom_line(aes(y = cases_corrected), col = 2) +   geom_hline(yintercept = 0, linetype = 3) +   facet_wrap(vars(geo_value), scales = \"free_y\", ncol = 1) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 counts\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/outliers.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Detect and correct outliers in signals","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/articles/slide.html","id":"slide-with-a-formula","dir":"Articles","previous_headings":"","what":"Slide with a formula","title":"Slide a computation over signal values","text":"first demonstrate apply 7-day trailing average daily cases order smooth signal, passing formula first argument epi_slide(). computation per state, first call group_by(). formula specified access columns present original epi_df object (must refer prefix .x$). can see, function epi_slide() returns epi_df object new column appended contains results (sliding), named slide_value default. can course change post hoc, can instead specify new name front using new_col_name argument:","code":"x %>%    group_by(geo_value) %>%    epi_slide(~ mean(.x$cases), n = 7) %>%   head(10) ## # A tibble: 10 × 4 ##    geo_value time_value cases slide_value ##    <chr>     <date>     <dbl>       <dbl> ##  1 ca        2020-03-01     6        6    ##  2 ca        2020-03-02     4        5    ##  3 ca        2020-03-03     6        5.33 ##  4 ca        2020-03-04    11        6.75 ##  5 ca        2020-03-05    10        7.4  ##  6 ca        2020-03-06    18        9.17 ##  7 ca        2020-03-07    26       11.6  ##  8 ca        2020-03-08    19       13.4  ##  9 ca        2020-03-09    23       16.1  ## 10 ca        2020-03-10    22       18.4 x <- x %>%    group_by(geo_value) %>%   epi_slide(~ mean(.x$cases), n = 7, new_col_name = \"cases_7dav\")  head(x, 10) ## # A tibble: 10 × 4 ##    geo_value time_value cases cases_7dav ##    <chr>     <date>     <dbl>      <dbl> ##  1 ca        2020-03-01     6       6    ##  2 ca        2020-03-02     4       5    ##  3 ca        2020-03-03     6       5.33 ##  4 ca        2020-03-04    11       6.75 ##  5 ca        2020-03-05    10       7.4  ##  6 ca        2020-03-06    18       9.17 ##  7 ca        2020-03-07    26      11.6  ##  8 ca        2020-03-08    19      13.4  ##  9 ca        2020-03-09    23      16.1  ## 10 ca        2020-03-10    22      18.4"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/slide.html","id":"slide-with-a-function","dir":"Articles","previous_headings":"","what":"Slide with a function","title":"Slide a computation over signal values","text":"can also pass function first argument epi_slide(). case, passed function must following argument structure: x, data frame column names original object; followed number named arguments; ending ... capture additional arguments. Recreating last example 7-day trailing average:","code":"x <- x %>%    group_by(geo_value) %>%    epi_slide(function(x, ...) mean(x$cases), n = 7, new_col_name = \"cases_7dav\")  head(x, 10) ## # A tibble: 10 × 4 ##    geo_value time_value cases cases_7dav ##    <chr>     <date>     <dbl>      <dbl> ##  1 ca        2020-03-01     6       6    ##  2 ca        2020-03-02     4       5    ##  3 ca        2020-03-03     6       5.33 ##  4 ca        2020-03-04    11       6.75 ##  5 ca        2020-03-05    10       7.4  ##  6 ca        2020-03-06    18       9.17 ##  7 ca        2020-03-07    26      11.6  ##  8 ca        2020-03-08    19      13.4  ##  9 ca        2020-03-09    23      16.1  ## 10 ca        2020-03-10    22      18.4"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/slide.html","id":"slide-the-tidy-way","dir":"Articles","previous_headings":"","what":"Slide the tidy way","title":"Slide a computation over signal values","text":"Perhaps convenient way setup computation epi_slide() pass expression tidy evaluation. case, can simply define name new column directly part expression, setting equal computation can access columns x name, just call dplyr::mutate(), dplyr verbs. example: simple sanity check, visualize 7-day trailing averages computed top original counts:  can see top right panel, looks like Texas moved weekly reporting COVID-19 cases summer 2021.","code":"x <- x %>%    group_by(geo_value) %>%    epi_slide(cases_7dav = mean(cases), n = 7)  head(x, 10) ## # A tibble: 10 × 4 ##    geo_value time_value cases cases_7dav ##    <chr>     <date>     <dbl>      <dbl> ##  1 ca        2020-03-01     6       6    ##  2 ca        2020-03-02     4       5    ##  3 ca        2020-03-03     6       5.33 ##  4 ca        2020-03-04    11       6.75 ##  5 ca        2020-03-05    10       7.4  ##  6 ca        2020-03-06    18       9.17 ##  7 ca        2020-03-07    26      11.6  ##  8 ca        2020-03-08    19      13.4  ##  9 ca        2020-03-09    23      16.1  ## 10 ca        2020-03-10    22      18.4 library(ggplot2) theme_set(theme_bw())  ggplot(x, aes(x = time_value)) +   geom_col(aes(y = cases, fill = geo_value), alpha = 0.5, show.legend = FALSE) +   geom_line(aes(y = cases_7dav, col = geo_value), show.legend = FALSE) +   facet_wrap(~ geo_value, scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 cases\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/slide.html","id":"running-a-local-forecaster","dir":"Articles","previous_headings":"","what":"Running a local forecaster","title":"Slide a computation over signal values","text":"complex example, create forecaster based local (time) autoregression AR model. AR models can fit numerous ways (using base R functions various packages), define “hand” provides advanced example sliding function epi_df object, allows us bit flexible defining probabilistic forecaster: one outputs just point prediction, notion uncertainty around . particular, forecaster output point prediction along 90% uncertainty band, represented predictive quantiles 5% 95% levels (lower upper endpoints uncertainty band). function defined , prob_ar(), probabilistic AR forecaster. lagsargument indicates lags use model, ahead indicates far ahead future make forecasts (encoded terms units time_value column; , days, working epi_df considered vignette). go ahead slide AR forecaster working epi_df COVID-19 cases. Note actually model cases_7dav column, operate scale smoothed COVID-19 cases. clearly equivalent, constant, modeling weekly sums COVID-19 cases. Note utilized argument ref_time_values perform sliding computation (, compute forecast) specific subset reference time values. get three columns fc_point, fc_lower, fc_upper correspond point forecast, lower upper endpoints 95% prediction band, respectively. (instead set as_list_col = TRUE call epi_slide(), gotten list column fc, element fc data frame named columns point, lower, upper.) finish , plot forecasts times (spaced months) last year, multiple horizons: 7, 14, 21, 28 days ahead. , encapsulate process generating forecasts simple function, can call times.  Two points worth making. First, AR model’s performance pretty spotty. various points time, can see forecasts volatile (point predictions place), overconfident (bands narrow), time. meant simple demo entirely unexpected given way AR model set . epipredict package, companion package epiprocess, offers suite predictive modeling tools can improve shortcomings simple AR model. Second, AR forecaster using finalized data, meaning, uses latest versions signal values (reported COVID-19 cases) available, training models making predictions historically. However, reflective provisional nature data must cope true forecast task. Training making predictions finalized data can lead overly optimistic sense accuracy; see, example, McDonald et al. (2021), references therein. Fortunately, epiprocess package provides data structure called epi_archive can used store data revisions, furthermore, epi_archive object knows slide computations correct version-aware sense (computation reference time \\(t\\), uses data available \\(t\\)). revisit example archive vignette.","code":"prob_ar <- function(y, lags = c(0, 7, 14), ahead = 7, min_train_window = 20,                      lower_level = 0.05, upper_level = 0.95, symmetrize = TRUE,                     intercept = FALSE, nonneg = TRUE) {      # Return NA if insufficient training data   if (length(y) < min_train_window + max(lags) + ahead) {     return(data.frame(point = NA, lower = NA, upper = NA))   }      # Build features and response for the AR model   dat <- do.call(     data.frame,      purrr::map(lags, function(j) lag(y, n = j))   )   names(dat) = paste0(\"x\", 1:ncol(dat))   if (intercept) dat$x0 = rep(1, nrow(dat))   dat$y <- lead(y, n = ahead)       # Now fit the AR model and make a prediction   obj <- lm(y ~ . + 0, data = dat)   point <- predict(obj, newdata = tail(dat, 1))      # Compute a band    r <- residuals(obj)   s <- ifelse(symmetrize, -1, NA) # Should the residuals be symmetrized?   q <- quantile(c(r, s * r), probs = c(lower_level, upper_level), na.rm = TRUE)   lower <- point + q[1]   upper <- point + q[2]      # Clip at zero if we need to, then return   if (nonneg) {      point = max(point, 0)      lower = max(lower, 0)      upper = max(upper, 0)    }   return(data.frame(point = point, lower = lower, upper = upper)) } fc_time_values <- seq(as.Date(\"2020-06-01\"),                        as.Date(\"2021-12-01\"),                        by = \"1 months\") x %>%    group_by(geo_value) %>%   epi_slide(fc = prob_ar(cases_7dav), n = 120,              ref_time_values = fc_time_values) %>%   head(10) ## # A tibble: 10 × 7 ##    geo_value time_value cases cases_7dav fc_point fc_lower fc_upper ##    <chr>     <date>     <dbl>      <dbl>    <dbl>    <dbl>    <dbl> ##  1 ca        2020-06-01  2439      2655.    2959.    2513.    3404. ##  2 ca        2020-07-01  7347      6722.    8051.    7394.    8708. ##  3 ca        2020-08-01  8614      8283.    7144.    5971.    8317. ##  4 ca        2020-09-01  4247      4704.    3989.    1896.    6082. ##  5 ca        2020-10-01  3505      3361.    3238.    1283.    5194. ##  6 ca        2020-11-01  4211      4442.    3760.    2083.    5438. ##  7 ca        2020-12-01 23637     15698.   18396.   16629.   20162. ##  8 ca        2021-01-01 50251     41114.   49691.   41828.   57554. ##  9 ca        2021-02-01 13112     17961    14528.    4442.   24615. ## 10 ca        2021-03-01  3030      5212.    4365.       0    14444. # Note the use of all_rows = TRUE (keeps all original rows in the output) k_week_ahead <- function(x, ahead = 7) {   x %>%      group_by(geo_value) %>%     epi_slide(fc = prob_ar(cases_7dav, ahead = ahead), n = 120,               ref_time_values = fc_time_values, all_rows = TRUE) %>%     mutate(target_date = time_value + ahead)  }  # First generate the forecasts, and bind them together z <- bind_rows(k_week_ahead(x, ahead = 7),                k_week_ahead(x, ahead = 14),                k_week_ahead(x, ahead = 21),                k_week_ahead(x, ahead = 28))  # Now plot them, on top of actual COVID-19 case counts  ggplot(z) +   geom_line(aes(x = time_value, y = cases_7dav), color = \"gray50\") +    geom_ribbon(aes(x = target_date, ymin = fc_lower, ymax = fc_upper,                   group = time_value), fill = 6, alpha = 0.4) +    geom_line(aes(x = target_date, y = fc_point, group = time_value)) +    geom_point(aes(x = target_date, y = fc_point, group = time_value),               size = 0.5) +    geom_vline(data = tibble(x = fc_time_values), aes(xintercept = x),               linetype = 2, alpha = 0.5) +   facet_wrap(vars(geo_value), scales = \"free_y\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(x = \"Date\", y = \"Reported COVID-19 cases\")"},{"path":"https://cmu-delphi.github.io/epiprocess/articles/slide.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Slide a computation over signal values","text":"document contains dataset modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jacob Bien. Contributor. Logan Brooks. Author. Rafael Catoia. Contributor. Daniel McDonald. Contributor. Quang Nguyen. Contributor. Evan Ray. Author. Dmitry Shemetov. Contributor. Ryan Tibshirani. Author, maintainer.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Brooks L, Ray E, Tibshirani R (2022). epiprocess: Tools basic signal processing epidemiology. R package version 1.0.0, https://cmu-delphi.github.io/epiprocess/.","code":"@Manual{,   title = {epiprocess: Tools for basic signal processing in epidemiology},   author = {Logan Brooks and Evan Ray and Ryan Tibshirani},   year = {2022},   note = {R package version 1.0.0},   url = {https://cmu-delphi.github.io/epiprocess/}, }"},{"path":"https://cmu-delphi.github.io/epiprocess/index.html","id":"epiprocess","dir":"","previous_headings":"","what":"Tools for basic signal processing in epidemiology","title":"Tools for basic signal processing in epidemiology","text":"package introduces common data structure epidemiological data sets measured space time, offers associated utilities perform basic signal processing tasks. See getting started guide vignettes examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/index.html","id":"epi_df-snapshot-of-a-data-set","dir":"","previous_headings":"","what":"epi_df: snapshot of a data set","title":"Tools for basic signal processing in epidemiology","text":"first main data structure epiprocess package called epi_df. simply tibble couple required columns, geo_value time_value. can number columns, can seen measured variables, also call signal variables. brief, epi_df object represents snapshot data set contains --date values signals variables, given time. convention, functions epiprocess package operate epi_df objects begin epi. example: epi_slide(), iteratively applying custom computation variable epi_df object sliding windows time; epi_cor(), computing lagged correlations variables epi_df object, (allowing grouping geo value, time value, variables). Functions package operate directly given variables begin epi. example: growth_rate(), estimating growth rate given signal given time values, using various methodologies; detect_outlr(), detecting outliers given signal time, using either built-custom methodologies.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/index.html","id":"epi_archive-full-version-history-of-a-data-set","dir":"","previous_headings":"","what":"epi_archive: full version history of a data set","title":"Tools for basic signal processing in epidemiology","text":"second main data structure package called epi_archive. special class (R6 format) wrapped around data table stores archive (version history) signal variables interest. convention, functions epiprocess package operate epi_df objects begin epix (“x” meant remind “archive”). just wrapper functions around public methods epi_archive R6 class. example: epix_as_of(), generating snapshot epi_df data archive, represents --date values signal variables, specified version; epix_merge(), merging two data archives , support filling missing values via last observation carried forward (LOCF); epix_slide(), sliding custom computation data archive local windows time, much like epi_slide epi_df object, one key difference: sliding computation given reference time t performed data available t.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/archive_cases_dv_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of daily doctor visits and cases from California, Florida, Texas, and New York in archive format — archive_cases_dv_subset","title":"Subset of daily doctor visits and cases from California, Florida, Texas, and New York in archive format — archive_cases_dv_subset","text":"data source based information outpatient visits, provided us health system partners, also contains confirmed COVID-19 cases based reports made available Center Systems Science Engineering Johns Hopkins University. example data ranges June 1, 2020 Dec 1, 2021, also limited California, Florida, Texas, New York.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/archive_cases_dv_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of daily doctor visits and cases from California, Florida, Texas, and New York in archive format — archive_cases_dv_subset","text":"","code":"archive_cases_dv_subset"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/archive_cases_dv_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of daily doctor visits and cases from California, Florida, Texas, and New York in archive format — archive_cases_dv_subset","text":"epi_archive data format. data table DT 129,638 rows 5 columns: geo_value geographic value associated row measurements. time_value time value associated row measurements. version time value specifying version row measurements. percent_cli percentage doctor’s visits CLI (COVID-like illness) computed medical insurance claims case_rate_7d_av 7-day average signal number new confirmed deaths due COVID-19 per 100,000 population, daily","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/archive_cases_dv_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of daily doctor visits and cases from California, Florida, Texas, and New York in archive format — archive_cases_dv_subset","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. Modifications: COVIDcast Epidata Doctor Visits API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes. 7-day average signals computed Delphi calculating moving averages preceding 7 days, signal June 7 average underlying data June 1 7, inclusive. Furthermore, data limited small number rows, signal names slightly altered, formatted tibble.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to epi_archive format — as_epi_archive","title":"Convert to epi_archive format — as_epi_archive","text":"Converts data frame, data table, tibble epi_archive object. See archive vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to epi_archive format — as_epi_archive","text":"","code":"as_epi_archive(   x,   geo_type,   time_type,   other_keys,   additional_metadata = list() )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to epi_archive format — as_epi_archive","text":"x data frame, data table, tibble, columns geo_value, time_value, version, additional number columns. geo_type Type geo values. missing, function attempt infer geo values present; fails, set \"custom\". time_type Type time values. missing, function attempt infer time values present; fails, set \"custom\". other_keys Character vector specifying names variables x considered key variables (language data.table) apart \"geo_value\", \"time_value\", \"version\". additional_metadata List additional metadata attach epi_archive object. metadata geo_type time_type fields; named entries passed list included well.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to epi_archive format — as_epi_archive","text":"epi_archive object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert to epi_archive format — as_epi_archive","text":"simply wrapper around new() method epi_archive class, example: equivalent :","code":"x <- as_epi_archive(df, geo_type = \"state\", time_type = \"day\") x <- epi_archive$new(df, geo_type = \"state\", time_type = \"day\")"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to epi_archive format — as_epi_archive","text":"","code":"df <- data.frame (geo_value  = c(replicate(2, \"ca\"), replicate(2, \"fl\")),                  county = c(1, 3, 2, 5),                  time_value = c(\"2020-06-01\",                  \"2020-06-02\",                  \"2020-06-01\",                  \"2020-06-02\"),                  version = c(\"2020-06-02\",                  \"2020-06-03\",                  \"2020-06-02\",                  \"2020-06-03\"),                  cases = c(1, 2, 3, 4),                  cases_rate = c(0.01, 0.02, 0.01, 0.05))  x <- df %>% as_epi_archive(geo_type = \"state\",                           time_type = \"day\",                           other_keys = \"county\")"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to epi_df format — as_epi_df","title":"Convert to epi_df format — as_epi_df","text":"Converts data frame tibble epi_df object. See getting started guide examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to epi_df format — as_epi_df","text":"","code":"as_epi_df(x, ...)  # S3 method for epi_df as_epi_df(x, ...)  # S3 method for tbl_df as_epi_df(x, geo_type, time_type, as_of, additional_metadata = list(), ...)  # S3 method for data.frame as_epi_df(x, geo_type, time_type, as_of, additional_metadata = list(), ...)  # S3 method for tbl_ts as_epi_df(x, geo_type, time_type, as_of, additional_metadata = list(), ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to epi_df format — as_epi_df","text":"x data.frame, tibble::tibble, tsibble::tsibble converted ... Additional arguments passed methods. geo_type Type geo values. missing, function attempt infer geo values present; fails, set \"custom\". time_type Type time values. missing, function attempt infer time values present; fails, set \"custom\". as_of Time value representing time given data available. example, as_of January 31, 2022, epi_df object created represent --date version data available January 31, 2022. as_of argument missing, current day-time used. additional_metadata List additional metadata attach epi_df object. metadata geo_type, time_type, as_of fields; named entries passed list included well.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to epi_df format — as_epi_df","text":"epi_df object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_epi_df.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Convert to epi_df format — as_epi_df","text":"epi_df: Simply returns epi_df object unchanged. tbl_df: input tibble x must contain columns geo_value time_value. columns preserved , treated measured variables. as_of missing, function try guess as_of, issue, version column x (present), as_of field metadata (stored attributes); fails, current day-time used. data.frame: Works analogously as_epi_df.tbl_df(). tbl_ts: Works analogously as_epi_df.tbl_df(), except tbl_ts class dropped, key variables (\"geo_value\") added metadata returned object, other_keys field.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_tsibble.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to tsibble format — as_tsibble.epi_df","title":"Convert to tsibble format — as_tsibble.epi_df","text":"Converts epi_df object tsibble, index taken time_value, key variables taken geo_value along others other_keys field metadata, else explicitly set.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_tsibble.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to tsibble format — as_tsibble.epi_df","text":"","code":"# S3 method for epi_df as_tsibble(x, key, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/as_tsibble.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to tsibble format — as_tsibble.epi_df","text":"x epi_df object. key Optional. additional keys (geo_value) add tsibble. ... additional arguments passed tsibble::as_tsibble()","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect outliers — detect_outlr","title":"Detect outliers — detect_outlr","text":"Applies one outlier detection methods given signal variable, optionally aggregates outputs create consensus result. See outliers vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect outliers — detect_outlr","text":"","code":"detect_outlr(   x = seq_along(y),   y,   methods = tibble::tibble(method = \"rm\", args = list(list()), abbr = \"rm\"),   combiner = c(\"median\", \"mean\", \"none\") )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect outliers — detect_outlr","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. methods tibble specifying method(s) use outlier detection, one row per method, following columns: method: Either \"rm\" \"stl\", custom function outlier detection; see details explanation. args: Named list arguments passed detection method. abbr: Abbreviation use naming output columns results method. combiner String, one \"median\", \"mean\", \"none\", specifying combine results different outlier detection methods thresholds determining whether particular observation classified outlier, well replacement value outliers.  \"none\", summarized results calculated. Note number methods (number rows) odd, \"median\" equivalent majority vote purposes determining whether given observation outlier.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect outliers — detect_outlr","text":"tibble number rows equal length(y) columns giving outlier detection thresholds replacement values detection method.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect outliers — detect_outlr","text":"outlier detection method, one per row passed methods tibble, function must take first two arguments x y, number additional arguments. function must return tibble number rows equal length(y), columns lower, upper, replacement, representing lower upper bounds considered outlier, posited replacement value, respectively. convenience, outlier detection method can specified (method column methods) string \"rm\", shorthand detect_outlr_rm(), detects outliers via rolling median; \"stl\", shorthand detect_outlr_stl(), detects outliers via STL decomposition.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect outliers — detect_outlr","text":"","code":"detection_methods = dplyr::bind_rows(    dplyr::tibble(method = \"rm\",           args = list(list(detect_negatives = TRUE,                            detection_multiplier = 2.5)),           abbr = \"rm\"),    dplyr::tibble(method = \"stl\",           args = list(list(detect_negatives = TRUE,                            detection_multiplier = 2.5,                            seasonal_period = 7)),           abbr = \"stl_seasonal\"),    dplyr::tibble(method = \"stl\",           args = list(list(detect_negatives = TRUE,                            detection_multiplier = 2.5,                            seasonal_period = NULL)),           abbr = \"stl_nonseasonal\"))   x <- incidence_num_outlier_example %>%    dplyr::select(geo_value,time_value,cases) %>%    as_epi_df() %>%    group_by(geo_value) %>%    mutate(outlier_info  = detect_outlr(      x = time_value, y = cases,      methods = detection_methods,      combiner = \"median\")) %>%    unnest(outlier_info)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_rm.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect outliers based on a rolling median — detect_outlr_rm","title":"Detect outliers based on a rolling median — detect_outlr_rm","text":"Detects outliers based distance rolling median specified terms multiples rolling interquartile range (IQR).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_rm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect outliers based on a rolling median — detect_outlr_rm","text":"","code":"detect_outlr_rm(   x = seq_along(y),   y,   n = 21,   log_transform = FALSE,   detect_negatives = FALSE,   detection_multiplier = 2,   min_radius = 0,   replacement_multiplier = 0 )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_rm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect outliers based on a rolling median — detect_outlr_rm","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. n Number time steps use rolling window. Default 21. log_transform log transform applied running outlier detection? Default FALSE. TRUE, zeros present, log transform padded 1. detect_negatives negative values automatically count outliers? Default FALSE. detection_multiplier Value determining far outlier detection thresholds rolling median, calculated (rolling median) +/- (detection multiplier) * (rolling IQR). Default 2. min_radius Minimum distance rolling median threshold, transformed scale. Default 0. replacement_multiplier Value determining far replacement values rolling median. replacement original value within detection thresholds, otherwise rounded nearest (rolling median) +/- (replacement multiplier) * (rolling IQR). Default 0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_rm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect outliers based on a rolling median — detect_outlr_rm","text":"tibble number rows equal length(y), columns lower, upper, replacement.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_rm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect outliers based on a rolling median — detect_outlr_rm","text":"","code":"# Detect outliers based on a rolling median incidence_num_outlier_example %>%   dplyr::select(geo_value,time_value,cases) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(outlier_info  = detect_outlr_rm(     x = time_value, y = cases)) %>%   unnest(outlier_info) #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-21 22:17:14 #>  #> # A tibble: 730 × 6 #> # Groups:   geo_value [2] #>    geo_value time_value cases lower upper replacement #>  * <chr>     <date>     <dbl> <dbl> <dbl>       <dbl> #>  1 fl        2020-06-01   667  530  2010          667 #>  2 nj        2020-06-01   486  150.  840.         486 #>  3 fl        2020-06-02   617  582. 1992.         617 #>  4 nj        2020-06-02   658  210.  771.         658 #>  5 fl        2020-06-03  1317  635  1975         1317 #>  6 nj        2020-06-03   541  270   702          541 #>  7 fl        2020-06-04  1419  713  1909         1419 #>  8 nj        2020-06-04   478  174.  790.         478 #>  9 fl        2020-06-05  1305  553  2081         1305 #> 10 nj        2020-06-05   825  118.  838.         825 #> # … with 720 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect outliers based on an STL decomposition — detect_outlr_stl","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"Detects outliers based seasonal-trend decomposition using LOESS (STL).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"","code":"detect_outlr_stl(   x = seq_along(y),   y,   n_trend = 21,   n_seasonal = 21,   n_threshold = 21,   seasonal_period = NULL,   log_transform = FALSE,   detect_negatives = FALSE,   detection_multiplier = 2,   min_radius = 0,   replacement_multiplier = 0 )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. n_trend Number time steps use rolling window trend. Default 21. n_seasonal Number time steps use rolling window seasonality. Default 21. n_threshold Number time steps use rolling window IQR outlier thresholds. seasonal_period Integer specifying period seasonality. example, daily data, period 7 means weekly seasonality. default NULL, meaning seasonal term included STL decomposition. log_transform log transform applied running outlier detection? Default FALSE. TRUE, zeros present, log transform padded 1. detect_negatives negative values automatically count outliers? Default FALSE. detection_multiplier Value determining far outlier detection thresholds rolling median, calculated (rolling median) +/- (detection multiplier) * (rolling IQR). Default 2. min_radius Minimum distance rolling median threshold, transformed scale. Default 0. replacement_multiplier Value determining far replacement values rolling median. replacement original value within detection thresholds, otherwise rounded nearest (rolling median) +/- (replacement multiplier) * (rolling IQR). Default 0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"tibble number rows equal length(y), columns lower, upper, replacement.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"STL decomposition computed using feasts package. computed, outlier detection method analogous rolling median method detect_outlr_rm(), except fitted values residuals STL decomposition taking place rolling median residuals rolling median, respectively. last set arguments, log_transform replacement_multiplier, exactly detect_outlr_rm().","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/detect_outlr_stl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect outliers based on an STL decomposition — detect_outlr_stl","text":"","code":"# Detects outliers based on a seasonal-trend decomposition using LOESS incidence_num_outlier_example %>%   dplyr::select(geo_value,time_value,cases) %>%   as_epi_df() %>%   group_by(geo_value) %>%   mutate(outlier_info  = detect_outlr_stl(     x = time_value, y = cases,     seasonal_period = 7 )) %>% # weekly seasonality for daily data   unnest(outlier_info) #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-21 22:17:14 #>  #> # A tibble: 730 × 6 #> # Groups:   geo_value [2] #>    geo_value time_value cases  lower upper replacement #>  * <chr>     <date>     <dbl>  <dbl> <dbl>       <dbl> #>  1 fl        2020-06-01   667 -1193. 1233.         667 #>  2 nj        2020-06-01   486   281.  762.         486 #>  3 fl        2020-06-02   617  -691. 1890.         617 #>  4 nj        2020-06-02   658   317.  891.         658 #>  5 fl        2020-06-03  1317  -144. 2396.        1317 #>  6 nj        2020-06-03   541   292.  809.         541 #>  7 fl        2020-06-04  1419   260. 2696.        1419 #>  8 nj        2020-06-04   478   315.  792.         478 #>  9 fl        2020-06-05  1305   548. 2950.        1305 #> 10 nj        2020-06-05   825   382.  835.         825 #> # … with 720 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"epi_archive object — epi_archive","title":"epi_archive object — epi_archive","text":"epi_archive R6 class contains data table along several relevant pieces metadata. data table can seen full archive (version history) signal variables interest.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"epi_archive object — epi_archive","text":"epi_archive R6 class contains data table DT, class data.table data.table package, (least) following columns: geo_value: geographic value associated row measurements. time_value: time value associated row measurements. version: time value specifying version row measurements. example, given row version January 15, 2022 time_value January 14, 2022, row contains measurements data January 14, 2022 available one day later. data table DT key variables geo_value, time_value, version, well others (can specified instantiating epi_archive object via other_keys argument, /set operating DT directly). can single row per unique combination key variables, thus key variables critical figuring generate snapshot data archive, given version. general, last observation carried forward (LOCF) used data recorded versions. Currently, deletions must represented revising row special state (e.g., making entries NA including special column flags data removed performing kind post-processing), archive unaware state . word caution: R6 objects, unlike objects R, reference semantics. primary consequence objects copied modified. can read Hadley Wickham's Advanced R book.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"metadata","dir":"Reference","previous_headings":"","what":"Metadata","title":"epi_archive object — epi_archive","text":"following pieces metadata included fields epi_archive object: geo_type: type geo values. time_type: type time values. additional_metadata: list additional metadata data archive. Unlike epi_df object, metadata epi_archive object x can accessed (altered) directly, x$geo_type x$time_type, etc. Like epi_df object, geo_type time_type fields metadata epi_archive object currently used downstream functions epiprocess package, serve useful bits information convey data set hand.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"generating-snapshots","dir":"Reference","previous_headings":"","what":"Generating Snapshots","title":"epi_archive object — epi_archive","text":"epi_archive object can used generate snapshot data epi_df format, represents --date values signal variables, specified version. accomplished calling as_of() method epi_archive object x. details method documented wrapper function epix_as_of().","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"sliding-computations","dir":"Reference","previous_headings":"","what":"Sliding Computations","title":"epi_archive object — epi_archive","text":"can run sliding computation epi_archive object, much like epi_slide() epi_df object. accomplished calling slide() method epi_archive object, works similarly way epi_slide() works epi_df object, one key difference: version-aware. , epi_archive object, sliding computation given reference time point t performed data available t. details slide() documented wrapper function epix_slide().","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"epi_archive object — epi_archive","text":"epi_archive$new() epi_archive$print() epi_archive$as_of() epi_archive$merge() epi_archive$slide() epi_archive$clone()","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"epi_archive object — epi_archive","text":"Creates new epi_archive object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$new(x, geo_type, time_type, other_keys, additional_metadata)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"epi_archive object — epi_archive","text":"x data frame, data table, tibble, columns geo_value, time_value, version, additional number columns. geo_type Type geo values. missing, function attempt infer geo values present; fails, set \"custom\". time_type Type time values. missing, function attempt infer time values present; fails, set \"custom\". other_keys Character vector specifying names variables x considered key variables (language data.table) apart \"geo_value\", \"time_value\", \"version\". additional_metadata List additional metadata attach epi_archive object. metadata geo_type time_type fields; named entries passed list included well.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"epi_archive object — epi_archive","text":"epi_archive object.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$print()"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"method-as-of-","dir":"Reference","previous_headings":"","what":"Method as_of()","title":"epi_archive object — epi_archive","text":"Generates snapshot epi_df format given version. See documentation wrapper function epix_as_of() details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$as_of(max_version, min_time_value = -Inf)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"method-merge-","dir":"Reference","previous_headings":"","what":"Method merge()","title":"epi_archive object — epi_archive","text":"Merges another data.table current one, allows post-filling NA values last observation carried forward (LOCF). See documentation wrapper function epix_merge() details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$merge(y, ..., locf = TRUE, nan = NA)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"method-slide-","dir":"Reference","previous_headings":"","what":"Method slide()","title":"epi_archive object — epi_archive","text":"Slides given function variables epi_archive object. See documentation wrapper function epix_as_of() details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$slide(   f,   ...,   n = 7,   group_by,   ref_time_values,   time_step,   new_col_name = \"slide_value\",   as_list_col = FALSE,   names_sep = \"_\",   all_rows = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"epi_archive object — epi_archive","text":"objects class cloneable method.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"epi_archive object — epi_archive","text":"","code":"epi_archive$clone(deep = FALSE)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_archive.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"epi_archive object — epi_archive","text":"deep Whether make deep clone.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_cor.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute correlations between variables in an epi_df object — epi_cor","title":"Compute correlations between variables in an epi_df object — epi_cor","text":"Computes correlations variables epi_df object, allowing grouping geo value, time value, variables. See correlation vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_cor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute correlations between variables in an epi_df object — epi_cor","text":"","code":"epi_cor(   x,   var1,   var2,   dt1 = 0,   dt2 = 0,   shift_by = geo_value,   cor_by = geo_value,   use = \"na.or.complete\",   method = c(\"pearson\", \"kendall\", \"spearman\") )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_cor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute correlations between variables in an epi_df object — epi_cor","text":"x epi_df object consideration. var1, var2 variables x correlate. dt1, dt2 Time shifts consider two variables, respectively, computing correlations. Negative shifts translate lag value positive shifts lead value; example, dt = -1, new value June 2 original value June 1; dt = 1, new value June 2 original value June 3; dt = 0, values left . Default 0 dt1 dt2. shift_by variables(s) group , time shifts. default geo_value. However, also use, example, shift_by = c(geo_value, age_group), assuming x column age_group, perform time shifts per geo value age group. omit grouping entirely, use cor_by = NULL. Note grouping always undone correlation computations. cor_by variable(s) group , correlation computations. geo_value, default, correlations computed geo value, time; time_value, correlations computed time, geo values. grouping can also specified using number columns x; example, can use cor_by = c(geo_value, age_group), assuming x column age_group, order compute correlations pair geo value age group. omit grouping entirely, use cor_by = NULL. Note grouping always done time shifts. use, method Arguments pass cor(), \"na..complete\" default use (different cor()) \"pearson\" default method (cor()).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_cor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute correlations between variables in an epi_df object — epi_cor","text":"tibble grouping columns first (geo_value, time_value, possibly others), column cor, gives correlation.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_cor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute correlations between variables in an epi_df object — epi_cor","text":"","code":"# linear association of case and death rates on any given day epi_cor(x = jhu_csse_daily_subset,          var1 = case_rate_7d_av,          var2 = death_rate_7d_av,          cor_by = \"time_value\") #> Warning: the standard deviation is zero #> Warning: the standard deviation is zero #> Warning: the standard deviation is zero #> # A tibble: 671 × 2 #>    time_value    cor #>    <date>      <dbl> #>  1 2020-03-01 NA     #>  2 2020-03-02 NA     #>  3 2020-03-03 NA     #>  4 2020-03-04  0.748 #>  5 2020-03-05  0.552 #>  6 2020-03-06  0.695 #>  7 2020-03-07  0.277 #>  8 2020-03-08 -0.225 #>  9 2020-03-09 -0.194 #> 10 2020-03-10 -0.226 #> # … with 661 more rows  # correlation of death rates and lagged case rates epi_cor(x = jhu_csse_daily_subset,          var1 = case_rate_7d_av,          var2 = death_rate_7d_av,          cor_by = time_value,          dt1 = -2) #> Warning: the standard deviation is zero #> # A tibble: 671 × 2 #>    time_value    cor #>    <date>      <dbl> #>  1 2020-03-01 NA     #>  2 2020-03-02 NA     #>  3 2020-03-03 NA     #>  4 2020-03-04  0.989 #>  5 2020-03-05  0.907 #>  6 2020-03-06  0.748 #>  7 2020-03-07  0.552 #>  8 2020-03-08 -0.157 #>  9 2020-03-09 -0.126 #> 10 2020-03-10 -0.162 #> # … with 661 more rows  # correlation grouped by location  epi_cor(x = jhu_csse_daily_subset,          var1 = case_rate_7d_av,          var2 = death_rate_7d_av,          cor_by = geo_value) #> # A tibble: 6 × 2 #>   geo_value   cor #>   <chr>     <dbl> #> 1 ca        0.571 #> 2 fl        0.487 #> 3 ga        0.465 #> 4 ny        0.279 #> 5 pa        0.708 #> 6 tx        0.743  # correlation grouped by location and incorporates lagged cases rates epi_cor(x = jhu_csse_daily_subset,          var1 = case_rate_7d_av,          var2 = death_rate_7d_av,          cor_by = geo_value,          dt1 = -2) #> # A tibble: 6 × 2 #>   geo_value   cor #>   <chr>     <dbl> #> 1 ca        0.615 #> 2 fl        0.576 #> 3 ga        0.525 #> 4 ny        0.327 #> 5 pa        0.734 #> 6 tx        0.776"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"epi_df object — epi_df","title":"epi_df object — epi_df","text":"epi_df tibble certain minimal column structure metadata. can seen snapshot data set contains --date values signal variables interest, given time.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"epi_df object — epi_df","text":"epi_df tibble (least) following columns: geo_value: geographic value associated row measurements. time_value: time value associated row measurements. columns can considered measured variables, also refer signal variables. epi_df object also metadata (least) following fields: geo_type: type geo values. time_type: type time values. as_of: time value given data available. Metadata epi_df object x can accessed (altered) via attributes(x)$metadata. first two fields list, geo_type time_type, can usually inferred geo_value time_value columns, respectively. currently used downstream functions epiprocess package, serve useful bits information convey data set hand. information coding given . last field list, as_of, one unique aspects epi_df object. brief, can think epi_df object single snapshot data set contains --date values signals variables, time specified as_of field. companion object epi_archive object, contains full version history given data set. Revisions common many types epidemiological data streams, paying attention data revisions can important sorts downstream data analysis modeling tasks. See documentation epi_archive details data versioning works epiprocess package (including generate epi_df objects, data snapshots, epi_archive object).","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_df.html","id":"geo-types","dir":"Reference","previous_headings":"","what":"Geo Types","title":"epi_df object — epi_df","text":"following geo types recognized epi_df. \"county\": observation corresponds U.S. county; coded 5-digit FIPS code. \"hrr\": observation corresponds U.S. hospital referral region (designed represent regional healthcare markets); 306 HRRs U.S; coded number (nonconsecutive, 1 457). \"state\": observation corresponds U.S. state; coded 2-digit postal abbreviation (lowercase); note Puerto Rico \"pr\" Washington D.C. \"dc\". \"hhs\": observation corresponds U.S. HHS region; coded number (consecutive, 1 10). \"nation\": observation corresponds country; coded ISO 31661- alpha-2 country codes (lowercase). unrecognizable geo type labeled \"custom\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_df.html","id":"time-types","dir":"Reference","previous_headings":"","what":"Time Types","title":"epi_df object — epi_df","text":"following time types recognized epi_df. \"day-time\": observation corresponds time given day (measured second); coded POSIXct object, .POSIXct(\"2022-01-31 18:45:40\"). \"day\": observation corresponds day; coded Date object, .Date(\"2022-01-31\"). \"week\": observation corresponds week; alignment can arbitrary (whether week starts Monday, Tuesday); coded Date object, representing start date week. \"yearweek\": observation corresponds week; alignment can arbitrary; coded tsibble::yearweek object, alignment stored week_start field attributes. \"yearmonth\": observation corresponds month; coded tsibble::yearmonth object. \"yearquarter\": observation corresponds quarter; coded tsibble::yearquarter object. \"year\": observation corresponds year; coded integer greater equal 1582. unrecognizable time type labeled \"custom\".","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Slide a function over variables in an epi_df object — epi_slide","title":"Slide a function over variables in an epi_df object — epi_slide","text":"Slides given function variables epi_df object. See slide vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slide a function over variables in an epi_df object — epi_slide","text":"","code":"epi_slide(   x,   f,   ...,   n = 7,   ref_time_values,   align = c(\"right\", \"center\", \"left\"),   before,   time_step,   new_col_name = \"slide_value\",   as_list_col = FALSE,   names_sep = \"_\",   all_rows = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slide a function over variables in an epi_df object — epi_slide","text":"x epi_df object consideration. f Function formula slide variables x. \"slide\" means apply function formula running window n time steps (one time step typically one day one week; see details explanation). function, f must take x, data frame column names original object; followed number named arguments; ending .... formula, f can operate directly columns accessed via .x$var, ~ mean(.x$var) compute mean column var sliding window n time steps. ... Additional arguments pass function formula specified via f. Alternatively, f missing, current argument interpreted expression tidy evaluation. See details. n Number time steps use running window. example, n = 7, one time step one day, alignment \"right\", produce value January 7 apply given function formula data January 1 7. Default 7. ref_time_values Time values sliding computations, meaning, element vector serves reference time point one sliding window. missing, set unique time values underlying data table, default. align One \"right\", \"center\", \"left\", indicating alignment sliding window relative reference time point. alignment \"center\" n even, one time point used reference time point . Default \"right\". Positive integer less n, specifying number time points use sliding window strictly reference time point. example, setting = n-1 setting align = \"right\". argument allows flexible specification alignment align parameter, specified, overrides align. time_step Optional function used define meaning one time step, specified, overrides default choice based time_value column. function must take positive integer return object class lubridate::period. example, can use time_step = lubridate::hours order set time step one hour (meaningful time_value class POSIXct). new_col_name String indicating name new column contain derivative values. Default \"slide_value\"; note setting new_col_name equal existing column name overwrite column. as_list_col new column stored list column? Default FALSE, case list object returned f unnested (using tidyr::unnest()), names resulting columns given prepending new_col_name names list elements. names_sep String specifying separator use tidyr::unnest() as_list_col = FALSE. Default \"_\". Using NULL drops prefix new_col_name entirely. all_rows all_rows = TRUE, rows x kept output; otherwise, one row time value x acts reference time value. Default FALSE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slide a function over variables in an epi_df object — epi_slide","text":"epi_df object given appending new column x, named according new_col_name argument.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Slide a function over variables in an epi_df object — epi_slide","text":"\"slide\" means apply function formula running window n time steps, unit (meaning one time step) implicitly defined way time_value column treats addition subtraction; example, time values coded Date objects, one time step one day, since .Date(\"2022-01-01\") + 1 equals .Date(\"2022-01-02\"). Alternatively, time step can set explicitly using time_step argument (specified override default choice based time_value column). less n time steps available given reference time value, epi_slide() still attempts perform computation anyway (require complete window). issue partial computations (run incomplete windows) therefore left user, either specified function formula f, post-processing. f missing, expression tidy evaluation can specified, example, : equivalent : Thus, clear, computation specified via expression tidy evaluation (first example, ), name new column inferred given expression overrides name passed explicitly new_col_name argument.","code":"epi_slide(x, cases_7dav = mean(cases), n = 7) epi_slide(x, function(x, ...) mean(x$cases), n = 7,           new_col_name = \"cases_7dav\")"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epi_slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slide a function over variables in an epi_df object — epi_slide","text":"","code":"# slide a 7-day trailing average formula on cases   jhu_csse_daily_subset %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), n = 7,              align = \"right\") #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-23 20:17:07 #>  #> # A tibble: 4,026 × 7 #> # Groups:   geo_value [6] #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # … with 4,016 more rows, and 1 more variable: cases_7dav <dbl>    # slide a left-aligned 7-day average   jhu_csse_daily_subset %>%   group_by(geo_value) %>%   epi_slide(cases_7dav = mean(cases), n = 7,              align = \"left\") #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-23 20:17:07 #>  #> # A tibble: 4,026 × 7 #> # Groups:   geo_value [6] #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> #>  1 ca        2020-03-01         0.00327         0            6        1.29 #>  2 ca        2020-03-02         0.00435         0            4        1.71 #>  3 ca        2020-03-03         0.00617         0            6        2.43 #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  #> # … with 4,016 more rows, and 1 more variable: cases_7dav <dbl>    # nested new columns  jhu_csse_daily_subset %>%   group_by(geo_value) %>%  epi_slide(a = data.frame(cases_2dav = mean(cases),                            cases_2dma = mad(cases)),            n = 2, as_list_col = TRUE) #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-23 20:17:07 #>  #> # A tibble: 4,026 × 7 #> # Groups:   geo_value [6] #>    geo_value time_value case_rate_7d_av death_rate_7d_av cases cases_7d_av a     #>  * <chr>     <date>               <dbl>            <dbl> <dbl>       <dbl> <lis> #>  1 ca        2020-03-01         0.00327         0            6        1.29 <df>  #>  2 ca        2020-03-02         0.00435         0            4        1.71 <df>  #>  3 ca        2020-03-03         0.00617         0            6        2.43 <df>  #>  4 ca        2020-03-04         0.00980         0.000363    11        3.86 <df>  #>  5 ca        2020-03-05         0.0134          0.000363    10        5.29 <df>  #>  6 ca        2020-03-06         0.0200          0.000363    18        7.86 <df>  #>  7 ca        2020-03-07         0.0294          0.000363    26       11.6  <df>  #>  8 ca        2020-03-08         0.0341          0.000363    19       13.4  <df>  #>  9 ca        2020-03-09         0.0410          0.000726    23       16.1  <df>  #> 10 ca        2020-03-10         0.0468          0.000726    22       18.4  <df>  #> # … with 4,016 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epiprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"epiprocess: Tools for basic signal processing in epidemiology — epiprocess","title":"epiprocess: Tools for basic signal processing in epidemiology — epiprocess","text":"package introduces common data structure epidemiological data sets measured space time, offers associated utilities perform basic signal processing tasks.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a snapshot from an epi_archive object — epix_as_of","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"Generates snapshot epi_df format epi_archive object, given version. See archive vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"","code":"epix_as_of(x, max_version, min_time_value = -Inf)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"x epi_archive object max_version Time value specifying max version permit snapshot. , snapshot comprise unique rows current archive data represent --date signal values, specified max_version (whose time values least min_time_value.) min_time_value Time value specifying min time value permit snapshot. Default -Inf, effectively means minimum considered.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"epi_df object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"simply wrapper around as_of() method epi_archive class, x epi_archive object, : equivalent :","code":"epix_as_of(x, max_version = v) x$as_of(max_version = v)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_as_of.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a snapshot from an epi_archive object — epix_as_of","text":"","code":"# warning message of data latency shown epix_as_of(x = archive_cases_dv_subset,            max_version = max(archive_cases_dv_subset$DT$version)) #> Warning: Getting data as of the latest version possible. For a variety of #> reasons, it is possible that we only have a preliminary picture of this #> version (e.g., the upstream source has updated it but we have not seen it due #> to latency in synchronization). Thus, the snapshot that we produce here might #> not be reproducible at a later time (e.g., when the archive has caught up in #> terms of synchronization). #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2021-12-01 #>  #> # A tibble: 2,192 × 4 #>    geo_value time_value percent_cli case_rate_7d_av #>  * <chr>     <date>           <dbl>           <dbl> #>  1 ca        2020-06-01        2.75            6.84 #>  2 ca        2020-06-02        2.57            6.82 #>  3 ca        2020-06-03        2.48            6.66 #>  4 ca        2020-06-04        2.41            6.98 #>  5 ca        2020-06-05        2.57            6.97 #>  6 ca        2020-06-06        2.63            6.66 #>  7 ca        2020-06-07        2.73            6.74 #>  8 ca        2020-06-08        3.04            6.67 #>  9 ca        2020-06-09        2.97            6.81 #> 10 ca        2020-06-10        2.99            7.13 #> # … with 2,182 more rows  # no warning shown epix_as_of(archive_cases_dv_subset, max_version = as.Date(\"2020-06-10\"))           #> An `epi_df` object, with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2020-06-10 #>  #> # A tibble: 36 × 4 #>    geo_value time_value percent_cli case_rate_7d_av #>  * <chr>     <date>           <dbl>           <dbl> #>  1 ca        2020-06-01        2.13            6.63 #>  2 ca        2020-06-02        1.96            6.45 #>  3 ca        2020-06-03        1.79            6.62 #>  4 ca        2020-06-04        1.63            6.64 #>  5 ca        2020-06-05        1.58            6.91 #>  6 ca        2020-06-06        1.34            6.76 #>  7 ca        2020-06-07       NA               6.75 #>  8 ca        2020-06-08       NA               6.90 #>  9 ca        2020-06-09       NA               7.02 #> 10 fl        2020-06-01        1.86            3.38 #> # … with 26 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge two epi_archive objects — epix_merge","title":"Merge two epi_archive objects — epix_merge","text":"Merges underlying data tables two epi_archive objects, allows post-filling NA values last observation carried forward (LOCF), overwrites first data table merged one. See archive vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge two epi_archive objects — epix_merge","text":"","code":"epix_merge(x, y, ..., locf = TRUE, nan = NA)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge two epi_archive objects — epix_merge","text":"x, y Two epi_archive objects join together, specifically, whose underlying data tables joined together. data table x overwritten joined data table. convenience, also allow y passed directly data.table (need epi_archive object). ... Named arguments pass data.table::merge.data.table(), used join (default settings function). example, passing = TRUE perform full join. locf LOCF used joining non-key columns? take latest version signal value propogate forward fill gaps appear merging. Default TRUE. nan NaN values treated NA values post-filling step?  Default NA, means treated NA values; ","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge two epi_archive objects — epix_merge","text":"Nothing; data table x overwritten merged one.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge two epi_archive objects — epix_merge","text":"simply wrapper around merge() method epi_archive class, x y epi_archive objects, : equivalent :","code":"epix_merge(x, y) x$merge(y)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge two epi_archive objects — epix_merge","text":"","code":"# create two example epi_archive datasets x <- archive_cases_dv_subset$DT %>%   dplyr::select(geo_value,time_value,version,case_rate_7d_av) %>%   as_epi_archive() y <- archive_cases_dv_subset$DT %>%   dplyr::select(geo_value,time_value,version,percent_cli) %>%   as_epi_archive()  # a full join stored in x epix_merge(x, y, all = TRUE) #>         geo_value time_value    version case_rate_7d_av percent_cli #>      1:        ca 2020-06-01 2020-06-02        6.628329          NA #>      2:        ca 2020-06-01 2020-06-06        6.628329    2.140116 #>      3:        ca 2020-06-01 2020-06-07        6.628329    2.140116 #>      4:        ca 2020-06-01 2020-06-08        6.628329    2.140379 #>      5:        ca 2020-06-01 2020-06-09        6.628329    2.114430 #>     ---                                                             #> 129634:        tx 2021-11-26 2021-11-29        7.957657    1.858596 #> 129635:        tx 2021-11-27 2021-11-28        7.174299          NA #> 129636:        tx 2021-11-28 2021-11-29        6.834681          NA #> 129637:        tx 2021-11-29 2021-11-30        8.841247          NA #> 129638:        tx 2021-11-30 2021-12-01        9.566218          NA"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Slide a function over variables in an epi_archive object — epix_slide","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"Slides given function variables epi_archive object. behaves similarly epi_slide(), key exception version-aware: sliding computation given reference time t performed data available t. See archive vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"","code":"epix_slide(   x,   f,   ...,   n = 7,   group_by,   ref_time_values,   time_step,   new_col_name = \"slide_value\",   as_list_col = FALSE,   names_sep = \"_\",   all_rows = FALSE )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"x epi_archive object. f Function formula slide variables x. \"slide\" means apply function formula running window n time steps (one time step typically one day one week). function, f must take x, data frame column names original object; followed number named arguments; ending .... formula, f can operate directly columns accessed via .x$var, ~ mean(.x$var) compute mean column var sliding window n time steps. ... Additional arguments pass function formula specified via f. Alternatively, f missing, current argument interpreted expression tidy evaluation. n Number time steps use running window. example, n = 7, one time step one day, produce value January 7 apply given function formula data January 1 7. Default 7. group_by variable(s) group slide computation. missing, keys underlying data table, excluding time_value version, used grouping. omit grouping entirely, use group_by = NULL. ref_time_values Time values sliding computations, meaning, element vector serves reference time point one sliding window. missing, set unique time values underlying data table, default. time_step Optional function used define meaning one time step, specified, overrides default choice based time_value column. function must take positive integer return object class lubridate::period. example, can use time_step = lubridate::hours order set time step one hour (meaningful time_value class POSIXct). new_col_name String indicating name new column contain derivative values. Default \"slide_value\"; note setting new_col_name equal existing column name overwrite column. as_list_col new column stored list column? Default FALSE, case list object returned f unnested (using tidyr::unnest()), names resulting columns given prepending new_col_name names list elements. names_sep String specifying separator use tidyr::unnest() as_list_col = FALSE. Default \"_\". Using NULL drops prefix new_col_name entirely. all_rows all_rows = TRUE, output one row per combination grouping variables unique time values underlying data table. Otherwise, one row output time value x acts reference time value. Default FALSE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"tibble whose columns : grouping variables, time_value, containing reference time values slide computation, column named according new_col_name argument, containing slide values.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"Two key distinctions inputs current function epi_slide(): epix_slide() uses windows always right-aligned (epi_slide(), custom alignments specified using align arguments). epix_slide() uses group_by specify grouping upfront (epi_slide(), accomplished preceding function call dplyr::group_by()). Apart , interfaces epix_slide() epi_slide() . Note outputs similar different: epix_slide() returns grouping variables, time_value, new columns sliding, whereas epi_slide() returns original variables plus new columns sliding. Furthermore, current function can considerably slower epi_slide(), two reasons: (1) must repeatedly fetch properly-versioned snapshots data archive (via as_of() method), (2) performs \"manual\" sliding sorts, benefit highly efficient slider package. reason, never used place epi_slide(), used version-aware sliding necessary (purpose). Finally, simply wrapper around slide() method epi_archive class, x epi_archive object, : equivalent :","code":"epix_slide(x, new_var = comp(old_var), n = 120) x$slide(x, new_var = comp(old_var), n = 120)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/epix_slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slide a function over variables in an epi_archive object — epix_slide","text":"","code":"# these dates are reference time points for the 3 day average sliding window # The resulting epi_archive ends up including data averaged from: # 0 day which has no results, for 2020-06-01 # 1 day, for 2020-06-02 # 2 days, for the rest of the results # never 3 days dur to data latency  time_values <- seq(as.Date(\"2020-06-01\"),                       as.Date(\"2020-06-15\"),                       by = \"1 day\") epix_slide(x = archive_cases_dv_subset,            f = ~ mean(.x$case_rate),            n = 3,            group_by = geo_value,            ref_time_values = time_values,            new_col_name = 'case_rate_3d_av') #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> Warning: Unknown or uninitialised column: `case_rate`. #> Warning: argument is not numeric or logical: returning NA #> # A tibble: 56 × 3 #>    geo_value time_value case_rate_3d_av #>    <chr>     <date>               <dbl> #>  1 ca        2020-06-02              NA #>  2 fl        2020-06-02              NA #>  3 ny        2020-06-02              NA #>  4 tx        2020-06-02              NA #>  5 ca        2020-06-03              NA #>  6 fl        2020-06-03              NA #>  7 ny        2020-06-03              NA #>  8 tx        2020-06-03              NA #>  9 ca        2020-06-04              NA #> 10 fl        2020-06-04              NA #> # … with 46 more rows"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate growth rate — growth_rate","title":"Estimate growth rate — growth_rate","text":"Estimates growth rate signal given points along underlying sequence. Several methodologies available; see growth rate vignette examples.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate growth rate — growth_rate","text":"","code":"growth_rate(   x = seq_along(y),   y,   x0 = x,   method = c(\"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\"),   h = 7,   log_scale = FALSE,   dup_rm = FALSE,   na_rm = FALSE,   ... )"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate growth rate — growth_rate","text":"x Design points corresponding signal values y. Default seq_along(y) (, equally-spaced points 1 length y). y Signal values. x0 Points estimate growth rate. Must subset x (extrapolation allowed). Default x. method Either \"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\", indicating method use growth rate calculation. first two local methods: run sliding fashion sequence (order estimate derivatives hence growth rates); latter two global methods: run entire sequence. See details explanation. h Bandwidth sliding window, method \"rel_change\" \"linear_reg\". See details explanation. log_scale growth rates estimated using parametrization log scale? See details explanation. Default FALSE. dup_rm check remove duplicates x (corresponding elements y) computation? methods might handle duplicate x values gracefully, whereas others might fail (either quietly loudly). Default FALSE. na_rm missing values removed computation? Default FALSE. ... Additional arguments pass method used estimate derivative.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate growth rate — growth_rate","text":"Vector growth rate estimates specified points x0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate growth rate — growth_rate","text":"growth rate function f defined continuously-valued parameter t defined f'(t) / f(t), f'(t) derivative f t. estimate growth rate signal discrete-time (can thought evaluations discretizations underlying function continuous-time), can therefore estimate derivative divide signal value (possibly smoothed version signal value). following methods available estimating growth rate: \"rel_change\": uses (B/- 1) / h, B average y second half sliding window bandwidth h centered reference point x0, average first half. can seen using first-difference approximation derivative. \"linear_reg\": uses slope linear regression y x sliding window centered reference point x0, divided fitted value linear regression x0. \"smooth_spline\": uses estimated derivative x0 smoothing spline fit x y, via stats::smooth.spline(), divided fitted value spline x0. \"trend_filter\": uses estimated derivative x0 polynomial trend filtering (discrete spline) fit x y, via genlasso::trendfilter(), divided fitted value discrete spline x0.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"log-scale","dir":"Reference","previous_headings":"","what":"Log Scale","title":"Estimate growth rate — growth_rate","text":"alternative view growth rate function f general given defining g(t) = log(f(t)), observing g'(t) = f'(t) / f(t). Therefore, method estimates derivative can simply applied log signal interest, light, method (\"rel_change\", \"linear_reg\", \"smooth_spline\", \"trend_filter\") log scale analog, can used setting log_scale = TRUE.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"sliding-windows","dir":"Reference","previous_headings":"","what":"Sliding Windows","title":"Estimate growth rate — growth_rate","text":"local methods, \"rel_change\" \"linear_reg\", use sliding window centered reference point bandiwidth h. words, sliding window consists points x whose distance reference point h. Note unit distance implicitly defined x variable; example, x vector Date objects, h = 7, reference point January 7, sliding window contains data January 1 14 (matching behavior epi_slide() n = 2 * h align = \"center\").","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/growth_rate.html","id":"additional-arguments","dir":"Reference","previous_headings":"","what":"Additional Arguments","title":"Estimate growth rate — growth_rate","text":"global methods, \"smooth_spline\" \"trend_filter\", additional arguments can specified via ... underlying estimation function. smoothing spline case, additional arguments passed directly stats::smooth.spline() (defaults exactly function). trend filtering case works bit differently: , custom set arguments allowed (distributed internally genlasso::trendfilter() genlasso::cv.trendfilter()): ord: order piecewise polynomial trend filtering fit. Default 3. maxsteps: maximum number steps take solution path terminating. Default 1000. cv: cross-validation used choose effective degrees freedom fit? Default TRUE. k: number folds cross-validation used. Default 3. df: desired effective degrees freedom trend filtering fit. cv = FALSE, df must positive integer; cv = TRUE, df must one \"min\" \"1se\" indicating selection rule use based cross-validation error curve: minimum 1-standard-error rule, respectively. Default \"min\" (going along default cv = TRUE). Note cv = FALSE, require df set user.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/incidence_num_outlier_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of JHU daily cases from California and Florida — incidence_num_outlier_example","title":"Subset of JHU daily cases from California and Florida — incidence_num_outlier_example","text":"data source confirmed COVID-19 cases based reports made available Center Systems Science Engineering Johns Hopkins University. example data snapshot Oct 28, 2021 captures cases June 1, 2020 May 31, 2021 limited California Florida.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/incidence_num_outlier_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of JHU daily cases from California and Florida — incidence_num_outlier_example","text":"","code":"incidence_num_outlier_example"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/incidence_num_outlier_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of JHU daily cases from California and Florida — incidence_num_outlier_example","text":"tibble 730 rows 3 variables: geo_value geographic value associated row measurements. time_value time value associated row measurements. cases Number new confirmed COVID-19 cases, daily","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/incidence_num_outlier_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of JHU daily cases from California and Florida — incidence_num_outlier_example","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. Modifications: COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes. Furthermore, data limited small number rows, signal names slightly altered, formatted tibble.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for epi_archive format — is_epi_archive","title":"Test for epi_archive format — is_epi_archive","text":"Test epi_archive format","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for epi_archive format — is_epi_archive","text":"","code":"is_epi_archive(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for epi_archive format — is_epi_archive","text":"x object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for epi_archive format — is_epi_archive","text":"TRUE object inherits epi_archive.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for epi_archive format — is_epi_archive","text":"","code":"is_epi_archive(jhu_csse_daily_subset) # FALSE (this is an epi_df, not epi_archive) #> [1] FALSE is_epi_archive(archive_cases_dv_subset) # TRUE #> [1] TRUE"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for epi_df format — is_epi_df","title":"Test for epi_df format — is_epi_df","text":"Test epi_df format","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for epi_df format — is_epi_df","text":"","code":"is_epi_df(x)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for epi_df format — is_epi_df","text":"x object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/is_epi_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for epi_df format — is_epi_df","text":"TRUE object inherits epi_df.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_county_level_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of JHU daily cases from counties in Massachusetts and Vermont — jhu_csse_county_level_subset","title":"Subset of JHU daily cases from counties in Massachusetts and Vermont — jhu_csse_county_level_subset","text":"data source confirmed COVID-19 cases deaths based reports made available Center Systems Science Engineering Johns Hopkins University. example data ranges Mar 1, 2020 Dec 31, 2021, limited Massachusetts Vermont.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_county_level_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of JHU daily cases from counties in Massachusetts and Vermont — jhu_csse_county_level_subset","text":"","code":"jhu_csse_county_level_subset"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_county_level_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of JHU daily cases from counties in Massachusetts and Vermont — jhu_csse_county_level_subset","text":"tibble 16,212 rows 5 variables: geo_value geographic value associated row measurements. time_value time value associated row measurements. cases Number new confirmed COVID-19 cases, daily county_name name county state_name full name state","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_county_level_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of JHU daily cases from counties in Massachusetts and Vermont — jhu_csse_county_level_subset","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. Modifications: COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes. 7-day average signals computed Delphi calculating moving averages preceding 7 days, signal June 7 average underlying data June 1 7, inclusive. Furthermore, data limited small number rows, signal names slightly altered, formatted tibble.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_daily_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of JHU daily cases and deaths from California, Florida, Texas, New York, Georgia, and Pennsylvania — jhu_csse_daily_subset","title":"Subset of JHU daily cases and deaths from California, Florida, Texas, New York, Georgia, and Pennsylvania — jhu_csse_daily_subset","text":"data source confirmed COVID-19 cases deaths based reports made available Center Systems Science Engineering Johns Hopkins University. example data ranges Mar 1, 2020 Dec 31, 2021, limited California, Florida, Texas, New York, Georgia, Pennsylvania.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_daily_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of JHU daily cases and deaths from California, Florida, Texas, New York, Georgia, and Pennsylvania — jhu_csse_daily_subset","text":"","code":"jhu_csse_daily_subset"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_daily_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of JHU daily cases and deaths from California, Florida, Texas, New York, Georgia, and Pennsylvania — jhu_csse_daily_subset","text":"tibble 4026 rows 6 variables: geo_value geographic value associated row measurements. time_value time value associated row measurements. case_rate_7d_av 7-day average signal number new confirmed COVID-19 cases per 100,000 population, daily death_rate_7d_av 7-day average signal number new confirmed deaths due COVID-19 per 100,000 population, daily cases Number new confirmed COVID-19 cases, daily cases_7d_av 7-day average signal number new confirmed COVID-19 cases, daily","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/jhu_csse_daily_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of JHU daily cases and deaths from California, Florida, Texas, New York, Georgia, and Pennsylvania — jhu_csse_daily_subset","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. Modifications: COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes. 7-day average signals computed Delphi calculating moving averages preceding 7 days, signal June 7 average underlying data June 1 7, inclusive. Furthermore, data limited small number rows, signal names slightly altered, formatted tibble.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/print.epi_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Base S3 methods for an epi_df object — print.epi_df","title":"Base S3 methods for an epi_df object — print.epi_df","text":"Print, summary, dplyr verbs (preserve class attributes) epi_df object. Prints variety summary statistics epi_df object, time range included geographic coverage. dplyr verbs epi_df objects, preserving class attributes.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/print.epi_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base S3 methods for an epi_df object — print.epi_df","text":"","code":"# S3 method for epi_df print(x, ...)  # S3 method for epi_df summary(object, ...)  # S3 method for epi_df arrange(.data, ...)  # S3 method for epi_df filter(.data, ...)  # S3 method for epi_df group_by(.data, ...)  # S3 method for epi_df group_modify(.data, ...)  # S3 method for epi_df mutate(.data, ...)  # S3 method for epi_df relocate(.data, ...)  # S3 method for epi_df rename(.data, ...)  # S3 method for epi_df slice(.data, ...)  # S3 method for epi_df ungroup(x, ...)  # S3 method for epi_df unnest(data, ...)"},{"path":"https://cmu-delphi.github.io/epiprocess/reference/print.epi_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base S3 methods for an epi_df object — print.epi_df","text":"x epi_df object. ... Additional arguments, compatibility summary(). Currently unused. object epi_df object. .data epi_df object. data epi_df object.","code":""},{"path":"https://cmu-delphi.github.io/epiprocess/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dplyr arrange, filter, group_by, group_modify, mutate, relocate, rename, slice, ungroup tidyr unnest tsibble as_tsibble","code":""}]
