---
title: 1. Slide a computation over signal values
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{1. Slide a computation over signal values}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

One of the most central tools in the `epiprocess` package is `epi_slide()`,
which is based on the family of functions provided by the
[`slider`](https://cran.r-project.org/web/packages/slider/) package. In
`epiprocess`, to "slide" means to apply a computation---represented as a
function or formula---over a running window of `n` time steps. Suitable
groupings can always be achieved by a preliminary call to `group_by()`.

By default, the meaning of one time step is inferred from the `time_type` of the
`epi_df` object under consideration. If `time_type` is "day", then one time step
is one day. The time step can also be specified manually in the call to
`epi_slide()`; you can read the documentation for more details. Furthermore, the
alignment of the running window used in `epi_slide()` can either be "right", 
"center", or "left"; the default is "right", and is what we use in this and most
other vignettes, without specifying otherwise.

Similar to the getting started guide, we'll fetch daily reported COVID-19 cases
for four U.S. states (note: new, not cumulative cases) using the
[`covidcast`](https://cmu-delphi.github.io/covidcast/covidcastR/) package, and
then convert this to `epi_df` format.

```{r, message = FALSE}
library(covidcast)
library(epiprocess)
library(dplyr)

x <- covidcast_signal(data_source = "jhu-csse", 
                      signal = "confirmed_incidence_num",
                      start_day = "2020-06-01", 
                      end_day = "2021-05-31",
                      geo_type = "state", 
                      geo_values = c("ca", "fl", "ny", "tx"))  %>%
  as_epi_df() %>%
  rename(cases = value) %>%
  select(geo_value, time_value, cases)
```

## Slide with a formula

We first demonstrate how to apply a 7-day trailing average to the daily cases in
order to smooth the signal, by passing in a formula for the first argument of
`epi_slide()`. To do this computation per state, we first call `group_by()`.

```{r}
x %>% 
  group_by(geo_value) %>% 
  epi_slide(~ mean(.x$cases), n = 7) %>%
  head(10)
```

The formula specified has access to all columns present in the original `epi_df`
object (and must refer to them with the prefix `.x$`). As we can see, the
function `epi_slide()` returns an `epi_df` object with a new column appended
that contains the results (from sliding), named `slide_value` as the default. We
can of course change this post hoc, or we can instead specify a new name up
front using the `new_col_name` argument:

```{r}
x <- x %>% 
  group_by(geo_value) %>% 
  epi_slide(~ mean(.x$cases), n = 7, new_col_name = "cases_7dav")

head(x, 10)
```

As a simple sanity check, we visualize the 7-day trailing averages computed on
top of the original counts:

```{r, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 6}
library(ggplot2)
theme_set(theme_bw())

ggplot(x, aes(x = time_value)) +
  geom_col(aes(y = cases, fill = geo_value), alpha = 0.5, show.legend = FALSE) +
  geom_line(aes(y = cases_7dav, col = geo_value), show.legend = FALSE) +
  facet_wrap(~ geo_value, scales = "free_y") +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Reported COVID-19 cases")
```

## Slide with a function 

We can also pass a function for the first argument in `epi_slide()`. In this
case, the passed function must have the following argument structure: `x`, a
data frame with the same column names as the original object; followed by any
number of named arguments; and ending with `...` to capture additional
arguments.  Recreating the last example of a 7-day trailing average:

```{r}
x <- x %>% 
  group_by(geo_value) %>% 
  epi_slide(function(x, ...) mean(x$cases), n = 7,
            new_col_name = "cases_7dav")

head(x, 10)
```

## Slide the tidy way

Perhaps the most convenient way to setup a computation in `epi_slide()` is to
pass in an expression for tidy evaluation. In this case, we can simply define
the name of the new column directly as part of the expression, setting it equal
to a computation in which we can access any columns of `x` by name, just as we
would in a call to `dplyr::summarize()`, or any of the `dplyr` verbs. For
example:

```{r}
x <- x %>% 
  group_by(geo_value) %>% 
  epi_slide(cases_7dav = mean(cases), n = 7)

head(x, 10)
```

## Running a local forecaster

As a more complicated example, we create a forecaster based on a local (in time)
autoregression or AR model. AR models can be fit in numerous ways (using base R
functions and various packages), but here we define it "by hand" both because it
provides a more advanced example of sliding a function over an `epi_df` object,
and because it allows us to be a bit more flexible in defining a *probabilistic*
forecaster: one that outputs not just a point prediction, but a notion of
uncertainty around this. In particular, our forecaster will output a point
prediction along with an 90\% uncertainty band, represented by a predictive
quantiles at the 5\% and 95\% levels (lower and upper endpoints of the
uncertainty band).

The function defined below, `prob_ar()`, is our probabilistic AR forecaster. The
`lags`argument indicates which lags to use in the model, and `ahead` indicates
how far ahead in the future to make forecasts (both are encoded in terms of the
units of the `time_value` column; so, days, in the working `epi_df` being
considered in this vignette).

```{r}
prob_ar <- function(v, lags = c(0, 7, 14), ahead = 7, min_train_window = 20, 
                    lower_level = 0.05, upper_level = 0.95, symmetrize = TRUE) {   
  # Return NA if insufficient training data
  if (length(v) < min_train_window + max(lags) + ahead) {
    return(data.frame(point = NA, lower = NA, upper = NA))
  }
  
  # Perform other simple checks
  stopifnot(all(lags >= 0), ahead > 0, max(lags) + ahead < length(v))
  
  # Go and fit the AR model
  y <- dplyr::lead(v, n = ahead)
  x <- do.call(cbind, purrr::map(lags, ~ dplyr::lag(v, n = .x)))
  fit <- lm(y ~ x, na.action = na.omit)

  # Make a prediction
  newx <- tail(x, 1)
  point <- drop(c(1, newx) %*% coef(fit))
  
  # Compute a band and return
  r <- residuals(fit)
  s <- ifelse(symmetrize, -1, NA) # Should the residuals be symmetrized?
  q <- quantile(c(r, s * r), probs = c(lower_level, upper_level), na.rm = TRUE)
  return(data.frame(point = point, lower = point + q[1], upper = point + q[2]))
}
```

Now we go ahead and slide this AR forecaster over the working `epi_df` of
COVID-19 cases. Note that we actually model the `cases_7dav` column, to operate
on the scale of smoothed COVID-19 cases. (This is clearly equivalent, up to a
constant, to modeling weekly sums of COVID-19 cases.)

```{r}
z <- x %>% 
  group_by(geo_value) %>%
  epi_slide(forecast = prob_ar(cases_7dav), n = 100, new_col_type = "list") %>%
  mutate(target_date = time_value + 7) 

tail(z, 3)
```

We can see that the `forecast` column is a list column (as specified in the call
to `slide_to_geo()`, which was needed since `prob_ar()` returns a data frame),
and we can use `tidyr::unnest()` to unnest it.

```{r}
z <- tidyr::unnest(z, forecast)
tail(z, 10)
```

Now we get three columns `point`, `lower`, and `upper` corresponding to the
point forecast, and the lower and upper endpoints of the 95\% prediction band,
respectively.

To finish off, we plot the forecasts at some times (spaced out by a few months)
over the last year, at multiple horizons (7, 14, and 28 days ahead). To do so,
we encapsulate the process of generating forecasts into a simple function, so
that we can call it a few times.

```{r, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 6}
k_week_ahead <- function(x, ahead = 7) {
  x %>% 
    group_by(geo_value) %>%
    epi_slide(forecast = prob_ar(cases_7dav, ahead = ahead),
              n = 100, new_col_type = "list") %>%
    mutate(target_date = time_value + ahead) %>%
    tidyr::unnest(forecast)
}

# First generate the forecasts, and bind them together
z <- bind_rows(k_week_ahead(x, ahead = 7),
               k_week_ahead(x, ahead = 14),
               k_week_ahead(x, ahead = 28))

# Now plot some of them, spaced apart by 2 months
z_to_show <- z %>%
  filter(time_value %in% 
           seq(as.Date("2020-08-01"), as.Date("2021-06-01"), by = "2 months"))

p <- ggplot(z_to_show, aes(x = target_date, y = point, group = time_value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "orchid", alpha = 0.5) +
  geom_line() + geom_point(size = 0.5) + 
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_wrap(vars(geo_value), scales = "free_y") +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Reported COVID-19 cases")
  
gginnards::append_layers(
  p, geom_line(data = z, aes(x = time_value, y = cases_7dav), 
               inherit.aes = FALSE, color = "gray50"), pos = "bottom")
```

Two points are worth making. First, the AR model's performance here is pretty
mixed. At various points in time, we can see that its forecasts are volatile
(its point predictions are all over the place), or overconfident (its bands are
too narrow), or both at the same time. This is only meant as a simple demo and
slightly more sophisticated AR models can go a long way. For example, the 
overconfidence in this example is due to the fact that the bands are based on 
quantiles of training residuals, and when the AR model fits well to the training
set, these can clearly be too small in magnitude.

Second, the AR forecaster here is using using finalized data, meaning, it uses
the signal values (reported COVID-19 cases) corresponding to the latest issue
dates available, for both training models and making predictions. However, this
is not reflective of the provisional nature of the data that it must cope with 
in a true forecast task. Training and making predictions on finalized data can 
lead to an overly optimismic sense of accuracy; see, for example, [McDonald et 
al. (2021)](https://www.medrxiv.org/content/10.1101/2021.06.22.21259346), and
references therein.

*todo; refer to relevant functionality, vignette on issues and archive objects, 
`epipred`, and so on*