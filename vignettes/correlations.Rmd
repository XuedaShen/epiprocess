---
title: 4. Compute correlations between signals
description: Compute correlations between signals over space and time.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{4. Compute correlations between signals}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The `epitools` package provides some simple functionality for computing the 
correlations between two signals, over space or time. In this vignette, we'll
examine state-level COVID-19 case and death rates, smoothed using a 7-day
trailing average.

```{r, message = FALSE}
library(covidcast)
library(epitools)
library(dplyr)

start_day <- "2020-03-01"
end_day <- "2021-10-11"

x <- covidcast_signal(data_source = "jhu-csse", 
                      signal = "confirmed_incidence_prop",
                      start_day = start_day, 
                      end_day = end_day,
                      geo_type = "state") %>%
  as.epi_signal() %>%
  rename(case_rates = value) %>%
  select(geo_value, time_value, case_rates) %>%
  slide_by_geo(slide_fun = ~ Mean(.x$case_rates), n = 7, 
               new_col_name = "case_rates") 

y <- covidcast_signal(data_source = "jhu-csse", 
                      signal = "deaths_incidence_prop",
                      start_day = start_day, 
                      end_day = end_day,
                      geo_type = "state") %>%
  as.epi_signal() %>%
  rename(death_rates = value) %>%
  select(geo_value, time_value, death_rates) %>%
  slide_by_geo(slide_fun = ~ Mean(.x$death_rates), n = 7, 
               new_col_name = "death_rates") 
  
x <- full_join(x, y, by = c("geo_value", "time_value"))
```

## Correlations grouped by time

The `grouped_cor()` function operates on an `epi_signal` object, and it requires
further specification of the variables to correlate, in its next two arguments 
(`var1` and `var2`). 

In general, we can specify any grouping variable (or combination of variables) 
in a call to `grouped_by()`, via the `by` argument. This potentially leads to
many ways to compute correlations. There are always at least two ways to compute
correlations in an `epi_signal`: grouping by time value, and by geo value. The 
former is obtained by setting `by = time_value`. 

```{r, message = FALSE, warning = FALSE}
library(ggplot2)
theme_set(theme_bw())

devtools::load_all("~/Dropbox/delphi/epitools")
z1 <- grouped_cor(x, case_rates, death_rates, by = time_value)

ggplot(z1, aes(x = time_value, y = cor)) + 
  geom_line() +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Correlation")
```

The above plot addresses the question: "on any given day, are case and death
rates linearly associated, across the U.S. states?". We might be interested in
broadening this question, instead asking: "on any given day, do higher case
rates tend to associate with higher death rates?", removing the dependence on a
linear relationship. The latter can be addressed using Spearman correlation,
accomplished by setting `method = "spearman"` in the call to `grouped_cor()`.
Spearman correlation is highly robust and invariant to monotone transformations.

## Lagged correlations

We might also be interested in how case rates associate with death rates in the
*future*. Using the `dt1` parameter in `grouped_cor()`, we can lag case rates
back any number of days we want, before calculating correlations. Below, we set 
`dt1 = -10`. This means that `var1 = case_rates` will be lagged by 10 days, so
that case rates on June 1st will be correlated with death rates on June 11th. 
(It might also help to think of it this way: death rates on a certain day will 
be correlated with case rates at an offset of -10 days.)

```{r, message = FALSE, warning = FALSE}
z2 <- grouped_cor(x, case_rates, death_rates, by = time_value, dt1 = -10)

z <- rbind(z1 %>% mutate(lag = 0), 
           z2 %>% mutate(lag = 10)) %>%
  mutate(lag = as.factor(lag))

ggplot(z, aes(x = time_value, y = cor)) +
  geom_line(aes(color = lag)) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  labs(x = "Date", y = "Correlation", col = "Lag") 
```

We can see that, generally, lagging the case rates back by 10 days improves the
correlations, confirming case rates are better correlated with death rates 10
days from now.

## Correlations grouped by state

The second option we have is to group by geo value, obtained by setting `by = 
geo_value`. We'll again look at correlations both for 0- and 10-day lagged case 
rates.

```{r, message = FALSE, warning = FALSE}
z1 <- grouped_cor(x, case_rates, death_rates, by = geo_value)
z2 <- grouped_cor(x, case_rates, death_rates, by = geo_value, dt1 = -10)

z <- rbind(z1 %>% mutate(lag = 0), 
           z2 %>% mutate(lag = 10)) %>%
  mutate(lag = as.factor(lag))

ggplot(z, aes(cor)) +
  geom_density(aes(fill = lag, col = lag), alpha = 0.5) +
  labs(x = "Correlation", y = "Density", fill = "Lag", col = "Lag") 
```

We can again see that, generally speaking, lagging the case rates back by 10 
days improves the correlations.

## More systematic lag analysis

Next we perform a more systematic investigation of the correlations over a broad
range of lag values. 

```{r, message = FALSE, warning = FALSE}
library(purrr)
lags = 0:35

z <- map_dfr(lags, function(lag) {
  grouped_cor(x, case_rates, death_rates, by = geo_value, dt1 = -lag) %>% 
    mutate(lag = lag) 
  })

z %>%
  group_by(lag) %>%
  summarize(mean = Mean(cor)) %>%
  ggplot(aes(x = lag, y = mean)) + 
  geom_line() + geom_point() +
  labs(x = "Lag", y = "Mean correlation")
```

We can see that some pretty clear curvature here in the mean correlation between 
case and death rates (where the correlations come from grouping by geo value) as
a function of lag. The maximum occurs at a lag of somewhere around 17 days.